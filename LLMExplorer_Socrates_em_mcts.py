import ast
import asyncio
from collections import defaultdict
import copy
from datetime import datetime
import json
import math
import random
import re
import os
from typing import Dict, List, Literal
import numpy as np
from pyvis.network import Network
from Swimming_Pool_Async.LLM_Core import LLM_Core
from Swimming_Pool_Async.Prompter import Prompter
from Swimming_Pool_Async.Tools import Tools
from Swimming_Pool_Async.Process_Controller import Process_Controller
from transformers import AutoTokenizer
from Swimming_Pool_Async.simple_rag import AsyncFaissRAG
import uuid
import logging
from pydantic import BaseModel, Field

class LLMExplorer_Socrates:
    def __init__( 
                  self,
                  llm: LLM_Core,
                  api_llm: LLM_Core = None,
                  api_llm2: LLM_Core = None,
                  initial_threshold=0.3,
                  current_score=None, 
                  max_iter=8, 
                  rag: AsyncFaissRAG = None, 
                  rag_j: AsyncFaissRAG = None, 
                  use_diversity_fusion: bool = False, 
                  save_dataset_path: str = "judge_training_data.jsonl", 
                  model_configs: dict = None,
                  elo_data_file: str = "judge_training_data.jsonl",
                  enable_elo_weighting: bool = True,
                  # [æ–°å¢] çŠ¶æ€è®°å½•å’Œå¯è§†åŒ–åŠŸèƒ½
                  enable_state_tracking: bool = False,
                  use_expert_prompt: bool = False,
                  state_save_path: str = "rollout_states",
                  auto_save_interval: int = 1,  # æ¯Næ¬¡è¿­ä»£è‡ªåŠ¨ä¿å­˜ä¸€æ¬¡
                  enable_visualization: bool = True
                    ):
        # åˆå§‹åŒ–ç»„ä»¶
        self.llm = llm
        self.api_llm = api_llm if api_llm else llm
        self.api_llm2 = api_llm2 if api_llm2 else llm
        self.current_score = current_score
        self.use_diversity_fusion = use_diversity_fusion
        self.prompter = Prompter()
        self.tools = Tools(filename="",tokenizer = "")
        self.rag = rag
        self.rag_j = rag_j
        self.process_controller = Process_Controller(llm = self.llm, tools = self.tools)
        self.logger = logging.getLogger(self.__class__.__name__)
        # [æ–°å¢] ä¿å­˜è·¯å¾„
        self.save_dataset_path = save_dataset_path
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if os.path.dirname(self.save_dataset_path):
            os.makedirs(os.path.dirname(self.save_dataset_path), exist_ok=True)
        
        # [æ–°å¢] æ¨¡å‹é…ç½®åˆ—è¡¨
        self.model_configs = model_configs or self._get_default_model_configs()
        self.model_cache = {}  # ç¼“å­˜å·²åˆ›å»ºçš„LLMå®ä¾‹
        
        # [æ–°å¢] ELOè¯„åˆ†ç³»ç»Ÿç›¸å…³
        self.elo_data_file = elo_data_file
        self.enable_elo_weighting = enable_elo_weighting
        self.current_elo_ratings = {}  # å½“å‰ELOåˆ†æ•°
        self.model_battle_stats = {}  # æ¨¡å‹å¯¹æˆ˜ç»Ÿè®¡
        # åˆå§‹åŒ–å‚æ•°
        self.threshold = initial_threshold
        self.max_iter = max_iter
        # åˆå§‹åŒ–æ•°æ®ç»“æ„
        self._initialize_data_structures(enable_state_tracking,
                                         state_save_path,
                                         auto_save_interval,
                                         enable_visualization,
                                         use_expert_prompt)
        
    def _initialize_data_structures(self, 
                                    enable_state_tracking,
                                    state_save_path,
                                    auto_save_interval,
                                    enable_visualization,
                                    use_expert_prompt):
        """åˆå§‹åŒ–æˆ–é‡ç½®æ‰€æœ‰æ•°æ®ç»“æ„ã€‚"""
        self.to_explore = []
        self.to_explore_reward = {} # å­˜å‚¨èåˆåçš„å¥–åŠ± Q(s)
        self.to_explore_judgeA_reward = {}
        self.Meta_Prompt_bank = {}
        self.visit_counts = {}
        self.history_bank = {}
        self.thinks_bank = {}
        self.think = False
        self.ucb_bank = {}
        self.fathers = {}
        self.evaluations_bank = {}
        self.childs = {}
        self.reward_imp_bank = {}
        self.answers_list = []
        self.max_rejected_usage = 1
        self.use_expert_prompt = use_expert_prompt
        self.system = None
        self.default_system = None
        self.query = None
        self.use_meta_prompt = True
        self.use_enhancce = False
        self.context = ""
        self.standard_criteria = self.prompter.default_standard_criteriaV2
        self.uid = ""
        self.evolved_meta_prompt = ""
        self.evolved_judgeA_prompt = self.prompter.Self_Critique_Judge_exp_default_system
        self.node_meta_prompts = {}
        self.judgeA_meta_prompts = {}
        self.score_before_judgeA = 0
        self.early_stop = False
        
        self.node_model_mapping = {}
        
        self.model_usage_queue = []  # æ¨¡å‹ä½¿ç”¨é˜Ÿåˆ—ï¼šå…ˆéå†æ‰€æœ‰æ¨¡å‹ï¼Œå†éšæœºé€‰æ‹©
        self.current_rollout_models = []  # å½“å‰rolloutå‘¨æœŸä¸­å·²ä½¿ç”¨çš„æ¨¡å‹
        self.rollout_round = 0  # å½“å‰rolloutè½®æ¬¡
        
        self.pairwise_relations = [] 
        # ç¼“å­˜ EBC è®¡ç®—å‡ºçš„å…¨å±€åˆ†æ•°
        self.ebc_global_scores = {}
        # ç¼“å­˜å±€éƒ¨ä»·å€¼
        self.local_values = {}
        self.Q_values = {}
        self.ebc_alpha = 0.9
        self.gamma = 0.1
        # æ‚äº¤èåˆç›¸å…³é…ç½®
        self.max_merges = 3 
        self.merge_trigger_iters = {5, 10, 15}
        self.merge_counter = 0
        self.max_reward = 10
        self.max_expand = 2
        self.class_tag = ""
        self.category = ""
        self.iter = 0

        self.total_prompt_tokens = 0
        self.total_reasoning_tokens = 0
        self.total_completion_tokens = 0
        self.total_tokens = 0
        self.total_api_calls = 0

        self.current_elo_ratings = {"GLOBAL": {}} 
        self.model_battle_stats = {"GLOBAL": {}}  

        self.enable_state_tracking = enable_state_tracking
        self.state_save_path = state_save_path
        self.auto_save_interval = auto_save_interval
        self.enable_visualization = enable_visualization
        
        if self.enable_state_tracking:
            self._initialize_state_tracking()

        # åˆå§‹åŒ–æ•°æ®æ¨¡æ¿
        self.data_template = {
            "model": self.llm.api_model,
            "messages": [],
            "temperature": 0.95,
            "top_p": 0.9,
            "stream": False,
        }
        self.extra_body = {
        }

        self.judge_model_configs = {
            "deepseek/deepseek-v3.1-terminus": {
                "temperature": 0.95,
                "top_p": 0.9,
                "extra_body": {
                "reasoning": {"enabled": False},
                "provider" : {
                    "order": ["novita/fp8"],
                    "allow_fallbacks": False
                            }
                            }
            },
            "gpt-oss-120b": {
                "temperature": 0.95,
                "top_p": 0.9,
                "extra_body": {
                    "include_reasoning": True,  # æ˜¾å¼å¼€å¯æ¨ç†
                    "reasoning_effort": "low"   # è®¾ç½®æ¨ç†ç­‰çº§ä¸º low
                            }
            },
            "default": {
                "temperature": 0.95,
                "top_p": 0.9,
                "extra_body": {}
            }
        }
    def reset(self):
        """é‡ç½®æ‰€æœ‰å‚¨å­˜çš„æ•°æ®ç»“æ„ä»¥ä¾¿é‡æ–°ä½¿ç”¨ã€‚"""
        print("æ­£åœ¨é‡ç½® LLMExplorer_Socrates å®ä¾‹çš„æ‰€æœ‰æ•°æ®ç»“æ„ã€‚")
        self._initialize_data_structures()
        if self.enable_state_tracking:
            self._initialize_state_tracking()

    def _record_token_usage(self, completion):
        """
        è®°å½•APIè°ƒç”¨çš„tokenä½¿ç”¨æƒ…å†µ

        Args:
            completion: OpenAI APIè¿”å›çš„completionå¯¹è±¡ï¼ŒåŒ…å«usageä¿¡æ¯
        """
        if completion and hasattr(completion, 'usage') and completion.usage:
            usage = completion.usage
            self.total_api_calls += 1
            self.total_prompt_tokens += getattr(usage, 'prompt_tokens', 0)
            self.total_completion_tokens += getattr(usage, 'completion_tokens', 0)
            self.total_tokens += getattr(usage, 'total_tokens', 0)

            # å¤„ç†reasoning tokensï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(usage, 'completion_tokens_details'):
                details = usage.completion_tokens_details
                if details and hasattr(details, 'reasoning_tokens'):
                    self.total_reasoning_tokens += getattr(details, 'reasoning_tokens', 0)

    # ================= [æ–°å¢] çŠ¶æ€è¿½è¸ªå’Œå¯è§†åŒ–ç³»ç»Ÿ =================
    
    def _initialize_state_tracking(self):
        """åˆå§‹åŒ–çŠ¶æ€è¿½è¸ªç³»ç»Ÿ"""
        import os
        from datetime import datetime
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        if not os.path.exists(self.state_save_path):
            os.makedirs(self.state_save_path)
        
        # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_id = f"rollout_{timestamp}_{uuid.uuid4().hex[:8]}"
        
        # çŠ¶æ€è¿½è¸ªæ•°æ®ç»“æ„
        self.state_history = []  # å­˜å‚¨æ¯æ¬¡è¿­ä»£çš„å®Œæ•´çŠ¶æ€
        self.operation_log = []  # å­˜å‚¨æ‰€æœ‰æ“ä½œçš„è¯¦ç»†æ—¥å¿—
        self.visualization_data = []  # å­˜å‚¨å¯è§†åŒ–æ•°æ®
        
        # æ–‡ä»¶è·¯å¾„
        self.state_file = os.path.join(self.state_save_path, f"{self.session_id}_state.json")
        self.operation_file = os.path.join(self.state_save_path, f"{self.session_id}_operations.jsonl")
        self.visualization_file = os.path.join(self.state_save_path, f"{self.session_id}_visualization.html")
        
        print(f"[çŠ¶æ€è¿½è¸ª] å·²åˆå§‹åŒ–ï¼Œä¼šè¯ID: {self.session_id}")
        print(f"[çŠ¶æ€è¿½è¸ª] çŠ¶æ€æ–‡ä»¶: {self.state_file}")
        
    def _record_operation(self, operation_type: str, data: dict, iteration: int = None):
        """è®°å½•æ“ä½œåˆ°æ—¥å¿—"""
        if not self.enable_state_tracking:
            return
            
        from datetime import datetime
        
        operation = {
            "timestamp": datetime.now().isoformat(),
            "iteration": iteration or self.iter,
            "operation_type": operation_type,
            "data": data
        }
        
        self.operation_log.append(operation)
        
        # å¼‚æ­¥å†™å…¥æ“ä½œæ—¥å¿—æ–‡ä»¶
        try:
            with open(self.operation_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(operation, ensure_ascii=False, default=str) + "\n")
        except Exception as e:
            print(f"[è­¦å‘Š] è®°å½•æ“ä½œå¤±è´¥: {e}")
    
    def _capture_state_snapshot(self):
        """æ•è·å½“å‰å®Œæ•´çŠ¶æ€å¿«ç…§"""
        if not self.enable_state_tracking:
            return
            
        # æ„å»ºçŠ¶æ€å¿«ç…§ï¼ˆæ·±æ‹·è´é‡è¦æ•°æ®ï¼‰
        snapshot = {
            "iteration": self.iter,
            "timestamp": datetime.now().isoformat(),
            "session_id": self.session_id,
            
            # æ ¸å¿ƒæ•°æ®ç»“æ„
            "answers_list": copy.deepcopy(self.answers_list),
            "to_explore": copy.deepcopy(self.to_explore),
            "to_explore_reward": copy.deepcopy(self.to_explore_reward),
            "visit_counts": copy.deepcopy(self.visit_counts),
            "ucb_bank": copy.deepcopy(self.ucb_bank),
            "fathers": copy.deepcopy(self.fathers),
            "childs": copy.deepcopy(self.childs),
            "evaluations_bank": copy.deepcopy(self.evaluations_bank),
            "node_meta_prompts": copy.deepcopy(self.node_meta_prompts),
            
            # EBCå’Œä»·å€¼è®¡ç®—
            "pairwise_relations": copy.deepcopy(self.pairwise_relations),
            "ebc_global_scores": copy.deepcopy(self.ebc_global_scores),
            "local_values": copy.deepcopy(self.local_values),
            "Q_values": copy.deepcopy(self.Q_values),
            
            # æ¨¡å‹ç›¸å…³
            "node_model_mapping": copy.deepcopy(self.node_model_mapping),
            "current_elo_ratings": copy.deepcopy(self.current_elo_ratings),
            "model_battle_stats": copy.deepcopy(self.model_battle_stats),
            "model_usage_queue": copy.deepcopy(self.model_usage_queue),
            "current_rollout_models": copy.deepcopy(self.current_rollout_models),
            "rollout_round": self.rollout_round,
            
            # é…ç½®å‚æ•°
            "max_iter": self.max_iter,
            "threshold": self.threshold,
            "use_diversity_fusion": self.use_diversity_fusion,
            "ebc_alpha": self.ebc_alpha,
            "gamma": self.gamma,
            
            # è¾“å…¥ä¿¡æ¯
            "query": self.query,
            "system": self.system,
            "domain": getattr(self, 'domain', 'é€šç”¨'),
            "class_tag": self.class_tag
        }
        
        self.state_history.append(snapshot)
        return snapshot
    
    def save_state(self, filepath: str = None):
        """æ‰‹åŠ¨ä¿å­˜å½“å‰çŠ¶æ€åˆ°æ–‡ä»¶"""
        if not self.enable_state_tracking:
            print("[è­¦å‘Š] çŠ¶æ€è¿½è¸ªæœªå¯ç”¨ï¼Œæ— æ³•ä¿å­˜çŠ¶æ€")
            return False
            
        filepath = filepath or self.state_file
        
        try:
            # æ•è·å½“å‰çŠ¶æ€
            current_state = self._capture_state_snapshot()
            
            # æ„å»ºå®Œæ•´ä¿å­˜æ•°æ®
            save_data = {
                "session_info": {
                    "session_id": self.session_id,
                    "save_timestamp": datetime.now().isoformat(),
                    "total_iterations": self.iter,
                    "state_tracking_enabled": True
                },
                "current_state": current_state,
                "state_history": self.state_history,
                "operation_count": len(self.operation_log)
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"[çŠ¶æ€è¿½è¸ª] çŠ¶æ€å·²ä¿å­˜åˆ°: {filepath}")
            return True
            
        except Exception as e:
            print(f"[é”™è¯¯] ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def load_state(self, filepath: str):
        """ä»æ–‡ä»¶åŠ è½½çŠ¶æ€å¹¶æ¢å¤"""
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                save_data = json.load(f)
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            if "current_state" not in save_data:
                raise ValueError("ä¿å­˜æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼šç¼ºå°‘current_state")
            
            current_state = save_data["current_state"]
            
            # æ¢å¤æ ¸å¿ƒæ•°æ®ç»“æ„
            self.answers_list = current_state.get("answers_list", [])
            self.to_explore = current_state.get("to_explore", [])
            self.to_explore_reward = current_state.get("to_explore_reward", {})
            self.visit_counts = current_state.get("visit_counts", {})
            self.ucb_bank = current_state.get("ucb_bank", {})
            self.fathers = current_state.get("fathers", {})
            self.childs = current_state.get("childs", {})
            self.evaluations_bank = current_state.get("evaluations_bank", {})
            self.node_meta_prompts = current_state.get("node_meta_prompts", {})
            
            # æ¢å¤EBCå’Œä»·å€¼è®¡ç®—
            self.pairwise_relations = current_state.get("pairwise_relations", [])
            self.ebc_global_scores = current_state.get("ebc_global_scores", {})
            self.local_values = current_state.get("local_values", {})
            self.Q_values = current_state.get("Q_values", {})
            
            # æ¢å¤æ¨¡å‹ç›¸å…³
            self.node_model_mapping = current_state.get("node_model_mapping", {})
            self.current_elo_ratings = current_state.get("current_elo_ratings", {"GLOBAL": {}})
            self.model_battle_stats = current_state.get("model_battle_stats", {"GLOBAL": {}})
            self.model_usage_queue = current_state.get("model_usage_queue", [])
            self.current_rollout_models = current_state.get("current_rollout_models", [])
            self.rollout_round = current_state.get("rollout_round", 0)
            
            # æ¢å¤é…ç½®å’ŒçŠ¶æ€
            self.iter = current_state.get("iteration", 0)
            self.query = current_state.get("query", "")
            self.system = current_state.get("system", "")
            self.domain = current_state.get("domain", "é€šç”¨")
            self.class_tag = current_state.get("class_tag", "")
            
            # æ¢å¤çŠ¶æ€è¿½è¸ªå†å²ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.enable_state_tracking:
                self.state_history = save_data.get("state_history", [])
                self.session_id = save_data.get("session_info", {}).get("session_id", self.session_id)
                
                # é‡æ–°è®¾ç½®æ–‡ä»¶è·¯å¾„
                self.state_file = os.path.join(self.state_save_path, f"{self.session_id}_continued_state.json")
                self.operation_file = os.path.join(self.state_save_path, f"{self.session_id}_continued_operations.jsonl")
                self.visualization_file = os.path.join(self.state_save_path, f"{self.session_id}_continued_visualization.html")
            
            print(f"[çŠ¶æ€æ¢å¤] æˆåŠŸåŠ è½½çŠ¶æ€ï¼Œå½“å‰è¿­ä»£: {self.iter}")
            print(f"[çŠ¶æ€æ¢å¤] èŠ‚ç‚¹æ•°: {len(self.answers_list)}, æ¢ç´¢åˆ—è¡¨: {len(self.to_explore)}")
            return True
            
        except Exception as e:
            print(f"[é”™è¯¯] åŠ è½½çŠ¶æ€å¤±è´¥: {e}")
            return False
    def create_interactive_visualization(self, filename: str = None):
        """åˆ›å»ºäº¤äº’å¼å¯è§†åŒ–HTML"""
        if not self.enable_state_tracking or not self.enable_visualization:
            print("[è­¦å‘Š] å¯è§†åŒ–åŠŸèƒ½æœªå¯ç”¨")
            return False
            
        filename = filename or self.visualization_file
        
        try:
            # ç”Ÿæˆå®Œæ•´çš„äº¤äº’å¼HTML
            html_content = self._generate_interactive_html()
            
            with open(filename, "w", encoding="utf-8") as f:
                f.write(html_content)
                
            print(f"[å¯è§†åŒ–] äº¤äº’å¼HTMLå·²ç”Ÿæˆ: {filename}")
            return True
            
        except Exception as e:
            print(f"[é”™è¯¯] ç”Ÿæˆå¯è§†åŒ–å¤±è´¥: {e}")
            return False
    
    def _generate_interactive_html(self):
        """ç”Ÿæˆå®Œæ•´çš„äº¤äº’å¼HTMLå†…å®¹"""
        # å‡†å¤‡æ•°æ®
        viz_data = self._prepare_visualization_data()
        
        html_template = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLaMA-Berry Arena æ ‘æœç´¢å¯è§†åŒ–</title>
    <script src="https://unpkg.com/vis-network/standalone/umd/vis-network.min.js"></script>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            text-align: center;
        }}
        .controls {{
            padding: 20px;
            background: #f8f9fa;
            border-bottom: 1px solid #e9ecef;
        }}
        .control-group {{
            display: inline-block;
            margin-right: 20px;
            margin-bottom: 10px;
        }}
        .control-group label {{
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
            color: #495057;
        }}
        .control-group input, .control-group select {{
            padding: 8px 12px;
            border: 1px solid #ced4da;
            border-radius: 4px;
            background: white;
        }}
        .btn {{
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-weight: bold;
            margin-right: 10px;
            margin-bottom: 10px;
        }}
        .btn-primary {{
            background: #007bff;
            color: white;
        }}
        .btn-success {{
            background: #28a745;
            color: white;
        }}
        .btn-warning {{
            background: #ffc107;
            color: #212529;
        }}
        .btn:hover {{
            opacity: 0.8;
        }}
        .main-content {{
            display: flex;
            height: 600px;
        }}
        .network-container {{
            flex: 1;
            position: relative;
        }}
        #network {{
            width: 100%;
            height: 100%;
            border: 1px solid #dee2e6;
        }}
        .sidebar {{
            width: 400px;
            background: #f8f9fa;
            padding: 20px;
            overflow-y: auto;
            border-left: 1px solid #dee2e6;
        }}
        .info-panel {{
            background: white;
            padding: 15px;
            margin-bottom: 15px;
            border-radius: 8px;
            border-left: 4px solid #007bff;
        }}
        .info-title {{
            font-weight: bold;
            color: #495057;
            margin-bottom: 10px;
        }}
        .info-content {{
            color: #6c757d;
            line-height: 1.4;
        }}
        .operation-log {{
            max-height: 300px;
            overflow-y: auto;
            background: #f1f3f4;
            padding: 10px;
            border-radius: 4px;
            margin-top: 10px;
        }}
        .log-entry {{
            margin-bottom: 8px;
            padding: 5px;
            background: white;
            border-radius: 3px;
            font-size: 12px;
        }}
        .timestamp {{
            color: #6c757d;
            font-weight: bold;
        }}
        .legend {{
            margin-top: 20px;
            padding: 15px;
            background: white;
            border-radius: 8px;
        }}
        .legend-item {{
            display: flex;
            align-items: center;
            margin-bottom: 8px;
        }}
        .legend-color {{
            width: 20px;
            height: 20px;
            border-radius: 50%;
            margin-right: 10px;
        }}
        .progress-bar {{
            background: #e9ecef;
            border-radius: 10px;
            height: 20px;
            margin: 10px 0;
            overflow: hidden;
        }}
        .progress-fill {{
            background: linear-gradient(90deg, #28a745, #20c997);
            height: 100%;
            transition: width 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: bold;
            font-size: 12px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸŒ² LLaMA-Berry Arena æ ‘æœç´¢å¯è§†åŒ–</h1>
            <p>ä¼šè¯ID: {viz_data['session_id']} | æ€»è¿­ä»£æ•°: {viz_data['total_iterations']}</p>
        </div>
        
        <div class="controls">
            <div class="control-group">
                <label>é€‰æ‹©è¿­ä»£</label>
                <select id="iterationSelect" onchange="loadIteration()">
                    {self._generate_iteration_options()}
                </select>
            </div>
            <div class="control-group">
                <label>æ’­æ”¾é€Ÿåº¦</label>
                <select id="playbackSpeed">
                    <option value="500">æ…¢é€Ÿ (0.5s)</option>
                    <option value="1000" selected>æ­£å¸¸ (1s)</option>
                    <option value="2000">å¿«é€Ÿ (2s)</option>
                </select>
            </div>
            <button class="btn btn-primary" onclick="playAnimation()">ğŸ¬ æ’­æ”¾åŠ¨ç”»</button>
            <button class="btn btn-warning" onclick="pauseAnimation()">â¸ï¸ æš‚åœ</button>
            <button class="btn btn-success" onclick="resetView()">ğŸ”„ é‡ç½®è§†å›¾</button>
            <button class="btn btn-primary" onclick="exportData()">ğŸ’¾ å¯¼å‡ºæ•°æ®</button>
        </div>
        
        <div class="main-content">
            <div class="network-container">
                <div id="network"></div>
                <div class="progress-bar">
                    <div class="progress-fill" id="progressBar" style="width: 0%">
                        è¿­ä»£ 0 / {viz_data['total_iterations']}
                    </div>
                </div>
            </div>
            
            <div class="sidebar">
                <div class="info-panel">
                    <div class="info-title">ğŸ“Š å½“å‰ç»Ÿè®¡</div>
                    <div class="info-content" id="statsContent">
                        èŠ‚ç‚¹æ€»æ•°: {len(self.answers_list)}<br>
                        æ¢ç´¢èŠ‚ç‚¹: {len(self.to_explore)}<br>
                        å½“å‰è¿­ä»£: {self.iter}
                    </div>
                </div>
                
                <div class="info-panel">
                    <div class="info-title">ğŸ¯ é€‰ä¸­èŠ‚ç‚¹ä¿¡æ¯</div>
                    <div class="info-content" id="nodeInfo">
                        ç‚¹å‡»èŠ‚ç‚¹æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
                    </div>
                </div>
                
                <div class="info-panel">
                    <div class="info-title">ğŸ“ˆ UCBæ’è¡Œæ¦œ</div>
                    <div class="info-content" id="ucbRanking">
                        {self._generate_ucb_ranking_html()}
                    </div>
                </div>
                
                <div class="info-panel">
                    <div class="info-title">ğŸ“ æ“ä½œæ—¥å¿—</div>
                    <div class="operation-log" id="operationLog">
                        {self._generate_operation_log_html()}
                    </div>
                </div>
                
                <div class="legend">
                    <div class="info-title">ğŸ¨ å›¾ä¾‹</div>
                    <div class="legend-item">
                        <div class="legend-color" style="background: #33FF57;"></div>
                        <span>æ ¹èŠ‚ç‚¹</span>
                    </div>
                    <div class="legend-item">
                        <div class="legend-color" style="background: linear-gradient(45deg, #ff6b6b, #feca57);"></div>
                        <span>è¯„åˆ†èŠ‚ç‚¹ (é¢œè‰²è¡¨ç¤ºåˆ†æ•°é«˜ä½)</span>
                    </div>
                    <div class="legend-item">
                        <div class="legend-color" style="background: #74b9ff;"></div>
                        <span>å½“å‰æœ€ä½³èŠ‚ç‚¹</span>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // å…¨å±€å˜é‡
        let network;
        let nodes, edges;
        let animationTimer;
        let currentIteration = 0;
        let isPlaying = false;
        
        // æ•°æ®
        const visualizationData = {json.dumps(viz_data, ensure_ascii=False, default=str)};
        
        // åˆå§‹åŒ–
        document.addEventListener('DOMContentLoaded', function() {{
            initializeNetwork();
            loadIteration();
        }});
        
        // ç½‘ç»œåˆå§‹åŒ–
        function initializeNetwork() {{
            const container = document.getElementById('network');
            
            const data = {{
                nodes: new vis.DataSet(),
                edges: new vis.DataSet()
            }};
            
            const options = {{
                nodes: {{
                    shape: 'dot',
                    size: 20,
                    font: {{
                        size: 14,
                        color: '#343a40'
                    }},
                    borderWidth: 2,
                    borderWidthSelected: 4
                }},
                edges: {{
                    width: 2,
                    color: {{
                        color: '#FF5733',
                        highlight: '#FF0000',
                        hover: '#FF0000'
                    }},
                    arrows: {{
                        to: {{ enabled: true, scaleFactor: 1 }}
                    }},
                    smooth: {{
                        type: 'continuous'
                    }}
                }},
                physics: {{
                    stabilization: {{ iterations: 100 }},
                    barnesHut: {{
                        gravitationalConstant: -30000,
                        centralGravity: 0.3,
                        springLength: 95,
                        springConstant: 0.04,
                        damping: 0.09,
                        avoidOverlap: 0.1
                    }}
                }},
                interaction: {{
                    hover: true,
                    selectConnectedEdges: true
                }},
                layout: {{
                    improvedLayout: true
                }}
            }};
            
            network = new vis.Network(container, data, options);
            
            // èŠ‚ç‚¹é€‰æ‹©äº‹ä»¶
            network.on('selectNode', function(params) {{
                if (params.nodes.length > 0) {{
                    showNodeDetails(params.nodes[0]);
                }}
            }});
            
            nodes = network.body.data.nodes;
            edges = network.body.data.edges;
        }}
        
        // åŠ è½½ç‰¹å®šè¿­ä»£çš„æ•°æ®
        function loadIteration() {{
            const select = document.getElementById('iterationSelect');
            currentIteration = parseInt(select.value);
            
            if (visualizationData.state_history && visualizationData.state_history[currentIteration]) {{
                const state = visualizationData.state_history[currentIteration];
                updateNetworkData(state);
                updateStats(state);
                updateProgressBar();
            }}
        }}
        
        // æ›´æ–°ç½‘ç»œæ•°æ®
        function updateNetworkData(state) {{
            const nodeData = [];
            const edgeData = [];
            
            // åˆ›å»ºèŠ‚ç‚¹
            state.answers_list.forEach((nodeText, index) => {{
                const rewards = state.to_explore_reward[nodeText] || [];
                const avgReward = rewards.length > 0 ? rewards.reduce((a, b) => a + b, 0) / rewards.length : 0;
                const ucbValue = state.ucb_bank[nodeText] || 0;
                
                // åˆ¤æ–­æ˜¯å¦ä¸ºæ ¹èŠ‚ç‚¹
                const isRoot = !state.fathers[nodeText];
                
                // æ ¹æ®åˆ†æ•°è®¾ç½®é¢œè‰²
                let color = '#74b9ff'; // é»˜è®¤è“è‰²
                if (isRoot) {{
                    color = '#33FF57'; // æ ¹èŠ‚ç‚¹ç»¿è‰²
                }} else if (avgReward > 0) {{
                    // æ ¹æ®åˆ†æ•°è®¾ç½®æ¸å˜è‰²
                    const intensity = Math.min(avgReward / 10, 1);
                    const r = Math.floor(255 * (1 - intensity) + 255 * intensity);
                    const g = Math.floor(255 * (1 - intensity) + 107 * intensity);
                    const b = Math.floor(255 * (1 - intensity) + 87 * intensity);
                    color = `rgb(${{r}}, ${{g}}, ${{b}})`;
                }}
                
                // è·å–æ¨¡å‹ä¿¡æ¯
                const modelInfo = state.node_model_mapping[nodeText];
                const modelName = modelInfo ? modelInfo.model_name : 'unknown';
                
                nodeData.push({{
                    id: nodeText,
                    label: `${{nodeText.substring(0, 20)}}...\\n[${{modelName}}]\\nUCB: ${{ucbValue.toFixed(2)}}`,
                    title: `å®Œæ•´å†…å®¹: ${{nodeText}}\\næ¨¡å‹: ${{modelName}}\\nå¹³å‡å¥–åŠ±: ${{avgReward.toFixed(2)}}\\nUCBå€¼: ${{ucbValue.toFixed(2)}}\\nè®¿é—®æ¬¡æ•°: ${{rewards.length}}`,
                    color: color,
                    size: Math.max(15, Math.min(40, 15 + rewards.length * 3))
                }});
            }});
            
            // åˆ›å»ºè¾¹
            Object.keys(state.fathers).forEach(child => {{
                const parent = state.fathers[child];
                if (parent) {{
                    edgeData.push({{
                        from: parent,
                        to: child,
                        id: `${{parent}}-${{child}}`
                    }});
                }}
            }});
            
            // æ›´æ–°ç½‘ç»œ
            nodes.clear();
            edges.clear();
            nodes.add(nodeData);
            edges.add(edgeData);
        }}
        
        // æ˜¾ç¤ºèŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
        function showNodeDetails(nodeId) {{
            const state = visualizationData.state_history[currentIteration];
            const rewards = state.to_explore_reward[nodeId] || [];
            const avgReward = rewards.length > 0 ? rewards.reduce((a, b) => a + b, 0) / rewards.length : 0;
            const modelInfo = state.node_model_mapping[nodeId];
            const metaPrompts = state.node_meta_prompts[nodeId] || [];
            
            const info = `
                <strong>èŠ‚ç‚¹å†…å®¹:</strong><br>
                <div style="max-height: 100px; overflow-y: auto; background: #f8f9fa; padding: 8px; border-radius: 4px; margin: 5px 0;">
                    ${{nodeId.substring(0, 200)}}${{nodeId.length > 200 ? '...' : ''}}
                </div>
                <strong>æ¨¡å‹ä¿¡æ¯:</strong> ${{modelInfo ? modelInfo.model_name : 'unknown'}}<br>
                <strong>å¹³å‡å¥–åŠ±:</strong> ${{avgReward.toFixed(4)}}<br>
                <strong>è®¿é—®æ¬¡æ•°:</strong> ${{rewards.length}}<br>
                <strong>UCBå€¼:</strong> ${{(state.ucb_bank[nodeId] || 0).toFixed(4)}}<br>
                <strong>Meta Prompts:</strong> ${{metaPrompts.length}} ä¸ª
            `;
            
            document.getElementById('nodeInfo').innerHTML = info;
        }}
        
        // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        function updateStats(state) {{
            const stats = `
                èŠ‚ç‚¹æ€»æ•°: ${{state.answers_list.length}}<br>
                æ¢ç´¢èŠ‚ç‚¹: ${{state.to_explore.length}}<br>
                å½“å‰è¿­ä»£: ${{state.iteration}}<br>
                UCBå‡å€¼: ${{Object.values(state.ucb_bank).length > 0 ? (Object.values(state.ucb_bank).reduce((a,b) => a+b, 0) / Object.values(state.ucb_bank).length).toFixed(2) : '0.00'}}<br>
                å¯¹æˆ˜å…³ç³»: ${{state.pairwise_relations.length}} å¯¹
            `;
            document.getElementById('statsContent').innerHTML = stats;
        }}
        
        // æ›´æ–°è¿›åº¦æ¡
        function updateProgressBar() {{
            const progress = (currentIteration / Math.max(1, visualizationData.total_iterations)) * 100;
            const progressBar = document.getElementById('progressBar');
            progressBar.style.width = progress + '%';
            progressBar.textContent = `è¿­ä»£ ${{currentIteration}} / ${{visualizationData.total_iterations}}`;
        }}
        
        // æ’­æ”¾åŠ¨ç”»
        function playAnimation() {{
            if (isPlaying) return;
            
            isPlaying = true;
            const speed = parseInt(document.getElementById('playbackSpeed').value);
            const totalIterations = visualizationData.total_iterations;
            
            animationTimer = setInterval(() => {{
                currentIteration++;
                if (currentIteration >= totalIterations) {{
                    currentIteration = 0;
                }}
                
                document.getElementById('iterationSelect').value = currentIteration;
                loadIteration();
            }}, speed);
        }}
        
        // æš‚åœåŠ¨ç”»
        function pauseAnimation() {{
            if (animationTimer) {{
                clearInterval(animationTimer);
                isPlaying = false;
            }}
        }}
        
        // é‡ç½®è§†å›¾
        function resetView() {{
            currentIteration = 0;
            document.getElementById('iterationSelect').value = 0;
            loadIteration();
            pauseAnimation();
            if (network) {{
                network.fit();
            }}
        }}
        
        // å¯¼å‡ºæ•°æ®
        function exportData() {{
            const dataStr = JSON.stringify(visualizationData, null, 2);
            const dataBlob = new Blob([dataStr], {{type: 'application/json'}});
            const url = URL.createObjectURL(dataBlob);
            const link = document.createElement('a');
            link.href = url;
            link.download = `rollout_data_${{visualizationData.session_id}}.json`;
            link.click();
            URL.revokeObjectURL(url);
        }}
    </script>
</body>
</html>
        """
        
        return html_template

    def _prepare_visualization_data(self):
        """å‡†å¤‡å¯è§†åŒ–æ•°æ®"""
        return {
            "session_id": getattr(self, 'session_id', 'unknown'),
            "total_iterations": self.iter,
            "state_history": getattr(self, 'state_history', []),
            "operation_log": getattr(self, 'operation_log', []),
            "config": {
                "max_iter": self.max_iter,
                "use_diversity_fusion": self.use_diversity_fusion,
                "ebc_alpha": self.ebc_alpha,
                "gamma": self.gamma
            }
        }
    def _generate_iteration_options(self):
        """ç”Ÿæˆè¿­ä»£é€‰æ‹©ä¸‹æ‹‰æ¡†é€‰é¡¹"""
        options = []
        if hasattr(self, 'state_history'):
            for i in range(len(self.state_history)):
                options.append(f'<option value="{i}">è¿­ä»£ {i}</option>')
        else:
            options.append('<option value="0">è¿­ä»£ 0</option>')
        return '\n'.join(options)
    
    def _generate_ucb_ranking_html(self):
        """ç”ŸæˆUCBæ’è¡Œæ¦œHTML"""
        if not self.ucb_bank:
            return "æš‚æ— UCBæ•°æ®"
        
        # æŒ‰UCBå€¼æ’åº
        sorted_nodes = sorted(self.ucb_bank.items(), key=lambda x: x[1], reverse=True)[:5]
        
        html = "<div style='font-size: 12px;'>"
        for i, (node, ucb_value) in enumerate(sorted_nodes, 1):
            node_preview = node[:30] + "..." if len(node) > 30 else node
            model_info = self.node_model_mapping.get(node, {})
            model_name = model_info.get("model_name", "unknown")
            
            html += f"""
            <div style='margin-bottom: 8px; padding: 5px; background: #f8f9fa; border-radius: 3px;'>
                <strong>#{i}</strong> UCB: {ucb_value:.3f}<br>
                <span style='color: #6c757d;'>{node_preview}</span><br>
                <span style='color: #007bff; font-size: 10px;'>[{model_name}]</span>
            </div>
            """
        html += "</div>"
        return html
    
    def _generate_operation_log_html(self):
        """ç”Ÿæˆæ“ä½œæ—¥å¿—HTML"""
        if not hasattr(self, 'operation_log') or not self.operation_log:
            return "æš‚æ— æ“ä½œæ—¥å¿—"
        
        html = ""
        # æ˜¾ç¤ºæœ€è¿‘çš„10ä¸ªæ“ä½œ
        recent_operations = self.operation_log[-10:] if len(self.operation_log) > 10 else self.operation_log
        
        for op in reversed(recent_operations):  # æœ€æ–°çš„åœ¨å‰
            timestamp = op.get('timestamp', '')
            if timestamp:
                timestamp = timestamp.split('T')[1].split('.')[0]  # åªæ˜¾ç¤ºæ—¶é—´éƒ¨åˆ†
            
            html += f"""
            <div class='log-entry'>
                <span class='timestamp'>{timestamp}</span> - 
                <strong>{op.get('operation_type', 'Unknown')}</strong>
                <div style='margin-top: 3px; color: #6c757d; font-size: 11px;'>
                    è¿­ä»£ {op.get('iteration', '?')}
                </div>
            </div>
            """
        
        return html
    def _get_default_model_configs(self):
        """è·å–é»˜è®¤çš„æ¨¡å‹é…ç½®åˆ—è¡¨"""
        return {
            "gemini-3-pro-preview": {
                "model_name": "gemini-3-pro-preview",
                "api_base": '<your-base-url>',
                "api_type": "openai",
                "api_key": '<your-api-key>',
                "anony_only": False,
                "sampling_params": {
                    "extra_body": {"enable_thinking": True}
                },
                "model_link": "https://aistudio.google.com/app/prompts/new_chat?model=gemini-3-pro-preview",
                "description": "From Google",
                "organization": "Google",
                "license": "Proprietary",
                "sampling_weight": 1
            },
        }

    def _select_random_model(self):
        """
        [ä¿®æ”¹ç‰ˆ] æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼š
        1. åˆå§‹é˜¶æ®µ / æ•°æ®ä¸è¶³é˜¶æ®µï¼šå¼ºåˆ¶å¾ªç¯éå†é˜Ÿåˆ—ï¼Œç¡®ä¿æ¯ä¸ªæ¨¡å‹éƒ½æœ‰æœºä¼šè¿è¡Œã€‚
        2. æˆç†Ÿé˜¶æ®µ (æ‰€æœ‰æ¨¡å‹å¯¹æˆ˜æ•° > min_battles)ï¼šåˆ‡æ¢ä¸ºåŸºäº Softmax+UCB çš„åŠ æƒéšæœºé‡‡æ ·ã€‚
        """
        # è¿‡æ»¤æ‰æƒé‡ä¸º0çš„æ¨¡å‹ï¼ˆè¢«ç¦ç”¨çš„æ¨¡å‹ï¼‰
        available_models = {
            key: config for key, config in self.model_configs.items() 
            if config.get("sampling_weight", 1) > 0
        }
        
        if not available_models:
            print("è­¦å‘Šï¼šæ²¡æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®ï¼Œä½¿ç”¨é»˜è®¤LLM")
            return self.llm, {"model_name": "default", "organization": "Unknown"}
        
        available_model_names = list(available_models.keys())
        
        if self.model_usage_queue:
            # é˜Ÿåˆ—ä¸ä¸ºç©ºï¼Œå¤„äºã€å¼ºåˆ¶éå†é˜¶æ®µã€‘
            selected_model_name = self.model_usage_queue.pop(0)
            selection_type = "éå†(æ•°æ®ç§¯ç´¯ä¸­)"
            # print(f"éå†é˜¶æ®µ - é€‰æ‹©æ¨¡å‹: {selected_model_name} (é˜Ÿåˆ—å‰©ä½™: {len(self.model_usage_queue)})")
            
        else:
            weights = [available_models[name]["sampling_weight"] for name in available_model_names]
            selected_model_name = random.choices(available_model_names, weights=weights)[0]
            # æ‰¾åˆ°æƒé‡æœ€å¤§å€¼å¯¹åº”çš„ç´¢å¼•ï¼Œç„¶åå–åå­—
            # max_weight_index = weights.index(max(weights))
            # selected_model_name = available_model_names[max_weight_index]
            selection_type = "æ™ºèƒ½é‡‡æ ·(ELO+UCB)"
            # print(f"æ™ºèƒ½é˜¶æ®µ - åŸºäºæƒé‡é€‰æ‹©: {selected_model_name} (æƒé‡: {available_models[selected_model_name]['sampling_weight']:.2f})")

        # --- æ ¸å¿ƒé€»è¾‘ä¿®æ”¹ç»“æŸ ---

        selected_config = available_models[selected_model_name]
        
        # ä»¥ä¸‹ä¿æŒåŸä»£ç ä¸å˜...
        
        # æ ¹æ®æ¨¡å‹é…ç½®è®¾ç½®thinkingæ¨¡å¼
        sampling_params = selected_config.get("sampling_params", {})
        extra_body = sampling_params.get("extra_body", {})
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨thinkingæ¨¡å¼
        thinking_enabled = False
        if "enable_thinking" in extra_body and extra_body["enable_thinking"]:
            thinking_enabled = True
            self.extra_body = extra_body
        elif "thinking" in extra_body:
            thinking_config = extra_body["thinking"]
            if isinstance(thinking_config, dict) and thinking_config.get("type") == "enabled":
                thinking_enabled = True
                self.extra_body = extra_body
        # 3. [æ–°å¢] æ£€æŸ¥ reasoning: {"enabled": True} (DeepSeek R1/SGLang é£æ ¼)
        elif "reasoning" in extra_body:
            reasoning_config = extra_body["reasoning"]
            self.extra_body = extra_body
            # ç¡®ä¿ reasoning æ˜¯å­—å…¸ï¼Œä¸” enabled ä¸º True
            if isinstance(reasoning_config, dict) and reasoning_config.get("enabled") is True:
                thinking_enabled = True
        elif "include_reasoning" in extra_body:
            reasoning_config = extra_body["include_reasoning"]
            self.extra_body = extra_body
            # ç¡®ä¿ reasoning æ˜¯å­—å…¸ï¼Œä¸” enabled ä¸º True
            if reasoning_config == True:
                thinking_enabled = True
        # è®¾ç½®self.think
        self.think = thinking_enabled
        print(f"[{selection_type}] é€‰æ‹©æ¨¡å‹: {selected_model_name} | Thinking: {thinking_enabled}")
        
        # æ„å»ºæ¨¡å‹ä¿¡æ¯
        model_info = {
            "model_key": selected_model_name,
            "model_name": selected_config["model_name"],
            "organization": selected_config.get("organization", "Unknown"),
            "api_base": selected_config["api_base"],
            "description": selected_config.get("description", ""),
            "selection_type": selection_type,
            "rollout_round": self.rollout_round,
            "thinking_enabled": thinking_enabled
        }
        
        # è®°å½•å½“å‰rolloutä¸­çš„æ¨¡å‹ä½¿ç”¨
        if selected_model_name not in self.current_rollout_models:
            self.current_rollout_models.append(selected_model_name)
        
        # æ£€æŸ¥ç¼“å­˜
        if selected_model_name in self.model_cache:
            return self.model_cache[selected_model_name], model_info
        
        # åˆ›å»ºæ–°çš„LLMå®ä¾‹
        try:
            llm_instance = LLM_Core(
                tokenizer=self.llm.tokenizer if hasattr(self.llm, 'tokenizer') else None,
                use_async=True,
                api_model=selected_config["model_name"],
                base_url=selected_config["api_base"],
                api_key=selected_config["api_key"]
            )
            
            self.model_cache[selected_model_name] = llm_instance
            return llm_instance, model_info
            
        except Exception as e:
            print(f"åˆ›å»ºæ¨¡å‹ {selected_model_name} å¤±è´¥: {e}")
            print("ä½¿ç”¨é»˜è®¤LLM")
            return self.llm, {"model_name": "default_fallback", "organization": "Unknown"}

    def _initialize_model_queue(self, available_model_names):
        """åˆå§‹åŒ–æ¨¡å‹ä½¿ç”¨é˜Ÿåˆ—ï¼Œå¯ä»¥é€‰æ‹©éšæœºæ‰“ä¹±é¡ºåº"""
        # å¤åˆ¶å¯ç”¨æ¨¡å‹åˆ—è¡¨
        queue = available_model_names.copy()
        
        # å¯é€‰ï¼šéšæœºæ‰“ä¹±éå†é¡ºåºï¼Œè®©æ¯æ¬¡è¿è¡Œçš„éå†é¡ºåºä¸åŒ
        random.shuffle(queue)
        
        self.model_usage_queue = queue
        print(f"åˆå§‹åŒ–æ¨¡å‹éå†é˜Ÿåˆ—: {queue}")

    def start_new_rollout(self):
        """å¼€å§‹æ–°çš„rolloutï¼Œé‡ç½®æ¨¡å‹é€‰æ‹©çŠ¶æ€"""
        self.rollout_round += 1
        previous_models = self.current_rollout_models.copy()
        self.current_rollout_models = []
        
        print(f"\n=== å¼€å§‹æ–°çš„rollout (ç¬¬{self.rollout_round}è½®) ===")
        print(f"ä¸Šä¸€è½®ä½¿ç”¨çš„æ¨¡å‹: {previous_models}")
        print(f"é˜Ÿåˆ—çŠ¶æ€: {len(self.model_usage_queue)} ä¸ªæ¨¡å‹å¾…éå†")
        
        # [æ–°å¢] åœ¨æ¯æ¬¡æ–°rolloutæ—¶æ›´æ–°ELOè¯„åˆ†å’Œæƒé‡
        self.update_elo_ratings()
        
        # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å·²éå†è¿‡ï¼Œå¯ä»¥é€‰æ‹©é‡æ–°åˆå§‹åŒ–é˜Ÿåˆ—
        if not self.model_usage_queue and self.rollout_round > 1:
            available_models = {
                key: config for key, config in self.model_configs.items() 
                if config.get("sampling_weight", 1) > 0
            }
            print("æ‰€æœ‰æ¨¡å‹å·²éå†å®Œæˆï¼Œåç»­å°†ä½¿ç”¨éšæœºé€‰æ‹©ç­–ç•¥")

    def calculate_elo(self, winner_rating: float, loser_rating: float, k: int = 32):
        """
        è®¡ç®— Elo åˆ†æ•°æ›´æ–°
        :param winner_rating: èµ¢å®¶çš„å½“å‰åˆ†æ•°
        :param loser_rating: è¾“å®¶çš„å½“å‰åˆ†æ•°
        :param k: K-å› å­ï¼Œå†³å®šåˆ†æ•°å˜åŠ¨çš„å¹…åº¦
        :return: (æ›´æ–°åçš„èµ¢å®¶åˆ†æ•°, æ›´æ–°åçš„è¾“å®¶åˆ†æ•°)
        """
        import math
        # è®¡ç®—èƒœç‡æœŸæœ›
        expected_winner = 1 / (1 + 10 ** ((loser_rating - winner_rating) / 400))
        expected_loser = 1 - expected_winner
        
        # æ›´æ–°åˆ†æ•°
        new_winner_rating = winner_rating + k * (1 - expected_winner)
        new_loser_rating = loser_rating + k * (0 - expected_loser)
        
        return new_winner_rating, new_loser_rating

    def load_elo_ratings_from_file(self):
        """
        ä»æ•°æ®æ–‡ä»¶ä¸­åŠ è½½å’Œè®¡ç®—ELOè¯„åˆ†
        """
        if not self.elo_data_file or not os.path.exists(self.elo_data_file):
            print(f"ELOæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æˆ–æœªæŒ‡å®š: {self.elo_data_file}")
            return
        
        print(f"æ­£åœ¨ä»æ–‡ä»¶è®¡ç®—ELOè¯„åˆ†: {self.elo_data_file}")
        
        # åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹çš„ELOåˆ†æ•°ä¸º1200
        model_elo = {}
        battle_stats = {}
        
        # åˆå§‹åŒ–é…ç½®ä¸­çš„æ‰€æœ‰æ¨¡å‹
        for model_key in self.model_configs.keys():
            model_elo[model_key] = 1200.0
            battle_stats[model_key] = {"win": 0, "loss": 0, "total": 0}
        
        # è¯»å–æ•°æ®å¹¶å¤„ç†å¯¹æˆ˜ç»“æœ
        battles_processed = 0
        try:
            with open(self.elo_data_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if not line.strip():
                        continue
                    try:
                        data = json.loads(line)
                        model_config = data.get("model_config", {})
                        
                        # æå–èµ¢å®¶å’Œè¾“å®¶çš„æ¨¡å‹key
                        chosen_model = model_config.get("chosen_model", {})
                        rejected_model = model_config.get("rejected_model", {})
                        
                        chosen_key = chosen_model.get("model_key")
                        rejected_key = rejected_model.get("model_key")
                        
                        if not chosen_key or not rejected_key or chosen_key == rejected_key:
                            continue
                        
                        # å¦‚æœæ¨¡å‹ä¸åœ¨å­—å…¸ä¸­ï¼Œæ·»åŠ å®ƒä»¬
                        if chosen_key not in model_elo:
                            model_elo[chosen_key] = 1200.0
                            battle_stats[chosen_key] = {"win": 0, "loss": 0, "total": 0}
                        if rejected_key not in model_elo:
                            model_elo[rejected_key] = 1200.0
                            battle_stats[rejected_key] = {"win": 0, "loss": 0, "total": 0}
                        
                        # æ›´æ–°ELOåˆ†æ•°
                        w_old = model_elo[chosen_key]
                        l_old = model_elo[rejected_key]
                        
                        w_new, l_new = self.calculate_elo(w_old, l_old)
                        
                        model_elo[chosen_key] = w_new
                        model_elo[rejected_key] = l_new
                        
                        # ç»Ÿè®¡å¯¹æˆ˜è®°å½•
                        battle_stats[chosen_key]["win"] += 1
                        battle_stats[chosen_key]["total"] += 1
                        battle_stats[rejected_key]["loss"] += 1
                        battle_stats[rejected_key]["total"] += 1
                        
                        battles_processed += 1
                        
                    except json.JSONDecodeError:
                        continue
                        
        except FileNotFoundError:
            print(f"ELOæ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {self.elo_data_file}")
            return
        
        # ä¿å­˜è®¡ç®—ç»“æœ
        self.current_elo_ratings = model_elo
        self.model_battle_stats = battle_stats
        
        print(f"ELOè¯„åˆ†è®¡ç®—å®Œæˆï¼Œå¤„ç†äº† {battles_processed} åœºå¯¹æˆ˜")
        
        # æ‰“å°æ’è¡Œæ¦œï¼ˆä»…æ˜¾ç¤ºé…ç½®ä¸­çš„æ¨¡å‹ï¼‰
        config_models = [(k, v) for k, v in model_elo.items() if k in self.model_configs]
        sorted_leaderboard = sorted(config_models, key=lambda x: x[1], reverse=True)
        
        print("\n" + "="*60)
        print(f"{'æ’å':<4} {'æ¨¡å‹':<25} {'ELOåˆ†æ•°':<10} {'èƒœç‡':<8} {'å¯¹æˆ˜æ•°'}")
        print("-"*60)
        
        for rank, (name, score) in enumerate(sorted_leaderboard, 1):
            stats = battle_stats.get(name, {"win": 0, "total": 0})
            win_rate = (stats["win"] / stats["total"] * 100) if stats["total"] > 0 else 0
            print(f"{rank:<4} {name:<25} {score:<10.1f} {win_rate:>6.1f}% {stats['total']:>8}")
        print("="*60)

    def update_model_weights_by_elo(self, temperature: float = 100.0, exploration_weight: float = 1.0):
        """
        [ä¿®æ”¹ç‰ˆ] æ ¹æ®ELOåˆ†æ•°å’Œä½¿ç”¨æ¬¡æ•°åŠ¨æ€è°ƒæ•´æ¨¡å‹é‡‡æ ·æƒé‡
        åº”ç”¨ç­–ç•¥ï¼š
        1. Softmax: å°†ELOåˆ†æ•°è½¬åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œä¿ç•™ç›¸å¯¹å·®è· (Exploitation)
        2. UCB (Upper Confidence Bound): ç»™äºˆå¯¹æˆ˜æ¬¡æ•°å°‘çš„æ¨¡å‹é¢å¤–åŠ æˆ (Exploration)
        
        :param temperature: æ¸©åº¦ç³»æ•° (T)ã€‚
               Tè¶Šå°ï¼Œæƒé‡è¶Šé›†ä¸­åœ¨æœ€å¼ºæ¨¡å‹ï¼ˆè´ªå©ªï¼‰ï¼›
               Tè¶Šå¤§ï¼Œæƒé‡åˆ†å¸ƒè¶Šå¹³ç¼“ã€‚å»ºè®® 50-200 ä¹‹é—´ã€‚
        :param exploration_weight: æ¢ç´¢æƒé‡ç³»æ•° (C)ã€‚
               æ§åˆ¶"å°è¯•æ–°æ¨¡å‹"çš„æ„æ„¿ã€‚å»ºè®® 0.5-2.0 ä¹‹é—´ã€‚
        """
        if not self.enable_elo_weighting or not self.current_elo_ratings:
            return
        
        print(f"\næ­£åœ¨æ ¹æ®ELOåˆ†æ•°æ›´æ–°æ¨¡å‹æƒé‡ (Softmax T={temperature}, UCB C={exploration_weight})...")
        
        # 1. ç­›é€‰åœ¨é…ç½®æ–‡ä»¶ä¸­å­˜åœ¨çš„æ¨¡å‹
        config_model_keys = [k for k in self.model_configs.keys() if k in self.current_elo_ratings]
        
        if len(config_model_keys) < 2:
            print("å¯ç”¨æ¨¡å‹æ•°é‡ä¸è¶³ï¼Œè·³è¿‡æƒé‡æ›´æ–°")
            return
            
        # è·å–ç›¸å…³æ•°æ®
        elos = {k: self.current_elo_ratings[k] for k in config_model_keys}
        battle_stats = self.model_battle_stats
        
        # è®¡ç®—æ€»å¯¹æˆ˜æ•° (ç”¨äº UCB åˆ†å­)
        total_battles = sum(s.get("total", 0) for s in battle_stats.values())
        # é¿å… log(0)
        log_total_battles = math.log(max(total_battles, 1))
        
        # 2. è®¡ç®— Softmax æ¦‚ç‡ (Exploitation éƒ¨åˆ†)
        # Step A: å‡å»æœ€å¤§å€¼é˜²æ­¢ exp æº¢å‡º (Shift Invariance)
        max_elo = max(elos.values())
        # Step B: è®¡ç®— exp( (elo - max) / T )
        exp_scores = {k: math.exp((v - max_elo) / temperature) for k, v in elos.items()}
        sum_exp = sum(exp_scores.values())
        # Step C: å½’ä¸€åŒ–
        softmax_probs = {k: v / sum_exp for k, v in exp_scores.items()}
        
        print(f"{'æ¨¡å‹':<35} | {'ELO':<8} | {'å¯¹æˆ˜æ•°':<6} | {'èƒœç‡é¡¹(Prob)':<10} | {'æ¢ç´¢é¡¹(UCB)':<10} | {'æ–°æƒé‡'}")
        print("-" * 100)
        
        # 3. ç»“åˆ UCB è®¡ç®—æœ€ç»ˆæƒé‡å¹¶æ›´æ–°
        for k in config_model_keys:
            # A. åŸºç¡€èƒœç‡åˆ† (æ¥è‡ª Softmax)
            prob_score = softmax_probs[k]
            
            # B. æ¢ç´¢åŠ æˆ (UCB Bonus)
            # å…¬å¼: C * sqrt( ln(Total) / (N_j + 1) )
            # åŠ  1 æ˜¯ä¸ºäº†é˜²æ­¢é™¤é›¶ï¼Œä¸”ç¡®ä¿ 0 æ¬¡å¯¹æˆ˜çš„æ–°æ¨¡å‹è·å¾—æœ€å¤§åŠ æˆ
            n_j = battle_stats.get(k, {}).get("total", 0)
            ucb_bonus = exploration_weight * math.sqrt(log_total_battles / (n_j + 1))
            
            # C. æœ€ç»ˆæƒé‡ (Prob + Bonus)
            # ä¹˜ä»¥ 10 æ˜¯ä¸ºäº†è®©æƒé‡æ•°å€¼åœ¨è‚‰çœ¼æŸ¥çœ‹æ—¶æ›´ç›´è§‚ (å˜æˆ 1.0 ~ 5.0 çš„é‡çº§)ï¼Œ
            # å¯¹ random.choices æ¥è¯´ï¼Œæƒé‡çš„ç»å¯¹å¤§å°ä¸å½±å“ï¼Œåªçœ‹ç›¸å¯¹æ¯”ä¾‹ã€‚
            final_weight = (prob_score + ucb_bonus) * 10
            
            # æ›´æ–°åˆ°é…ç½®ä¸­
            old_weight = self.model_configs[k].get("sampling_weight", 1.0)
            self.model_configs[k]["sampling_weight"] = final_weight
            
            print(f"{k:<35} | {elos[k]:<8.1f} | {n_j:<6} | {prob_score:<10.4f} | {ucb_bonus:<10.4f} | {final_weight:.4f}")
            
        print("-" * 100)

    def update_elo_ratings(self):
        """
        åœ¨æ¯æ¬¡rolloutæ—¶æ›´æ–°ELOè¯„åˆ†å’Œæƒé‡
        """
        if self.enable_elo_weighting and self.elo_data_file:
            self.load_elo_ratings_from_file()
            self.update_model_weights_by_elo()

    def get_model_usage_stats(self):
        """è·å–æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "rollout_round": self.rollout_round,
            "models_in_queue": len(self.model_usage_queue),
            "models_used_this_round": self.current_rollout_models.copy(),
            "total_nodes": len(self.node_model_mapping),
            "model_distribution": {}
        }
        
        # ç»Ÿè®¡æ¯ä¸ªæ¨¡å‹çš„ä½¿ç”¨æ¬¡æ•°
        for node, model_info in self.node_model_mapping.items():
            model_name = model_info.get("model_name", "unknown")
            if model_name not in stats["model_distribution"]:
                stats["model_distribution"][model_name] = {
                    "count": 0,
                    "selection_types": {"éå†": 0, "éšæœº": 0}
                }
            stats["model_distribution"][model_name]["count"] += 1
            selection_type = model_info.get("selection_type", "æœªçŸ¥")
            if selection_type in stats["model_distribution"][model_name]["selection_types"]:
                stats["model_distribution"][model_name]["selection_types"][selection_type] += 1
        
        return stats

    def _save_judge_data(self, prompt: str, evaluation_object: BaseModel, chosen_model_info: dict = None, rejected_model_info: dict = None):
        """
        [æ–°å¢] å°†è¯„æµ‹çš„ Prompt å’Œæ¨¡å‹çš„ç»“æ„åŒ–è¾“å‡ºä¿å­˜ä¸º JSONL æ ¼å¼ã€‚
        æ ¼å¼éµå¾ªå¸¸è§çš„ SFT æ•°æ®æ ¼å¼ï¼š{"messages": [{"role": "user",...}, {"role": "assistant",...}]}
        [ä¿®æ”¹] æ·»åŠ æ¨¡å‹å¯¹æˆ˜ä¿¡æ¯ï¼Œä½¿å…¶å¯ä»¥ä½œä¸ºELOè®¡ç®—çš„æ•°æ®æº
        """
        try:
            # è·å– Pydantic æ¨¡å‹çš„ JSON å­—ç¬¦ä¸²è¡¨ç¤º (ä½œä¸º Assistant çš„å›å¤)
            # å…¼å®¹ Pydantic v1 (.json()) å’Œ v2 (.model_dump_json())
            if hasattr(evaluation_object, 'model_dump_json'):
                response_content = evaluation_object.model_dump_json(indent=2, ensure_ascii=False)
            else:
                response_content = evaluation_object.json(indent=2, ensure_ascii=False)

            # æ„å»ºè®­ç»ƒæ•°æ®æ¡ç›®
            entry = {
                "messages": [
                    {"role": "user", "content": prompt},
                    {"role": "assistant", "content": response_content}
                ],
                "metadata": {
                    "source": "LLMExplorer_Socrates_Gen",
                    "timestamp": str(uuid.uuid4()) # æˆ–è€…ç”¨æ—¶é—´æˆ³
                }
            }
            
            # [æ–°å¢] æ·»åŠ æ¨¡å‹å¯¹æˆ˜ä¿¡æ¯ï¼Œä½¿å…¶å¯ä»¥ä½œä¸ºELOæ•°æ®æº
            if chosen_model_info and rejected_model_info:
                entry["model_config"] = {
                    "chosen_model": chosen_model_info,
                    "rejected_model": rejected_model_info,
                    "strategy": " Em-Mcts (EBC + Bradley-Terry) + Arena Model Selection"
                }

            # è¿½åŠ å†™å…¥æ–‡ä»¶ (JSONL)
            with open(self.save_dataset_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
                
        except Exception as e:
            print(f"[Warning] ä¿å­˜è®­ç»ƒæ•°æ®å¤±è´¥: {e}")

    def calculate_ebc_scores(self) -> Dict[str, float]:
        """
        [ä¿®æ­£ç‰ˆ] ç»„ä»¶ä¸‰ï¼šEnhanced Borda Count (EBC) æ ¸å¿ƒç®—æ³•
        æ ¹æ®è®ºæ–‡  Em-Mcts å®ç°ï¼š
        1. æ„å»ºåå¥½çŸ©é˜µ M
        2. è®¡ç®—ä¼ é€’é—­åŒ… C
        3. è®¡ç®— Borda Count (æˆ˜èƒœçš„èŠ‚ç‚¹æ•°)
        4. è®¡ç®—å…¨å±€åˆ†ä½æ•°åˆ†æ•° Qg = 1 - (rank - 1) / (N - 1)
        """
        # 1. è·å–æ‰€æœ‰å‚ä¸è¿‡æ¯”è¾ƒçš„å”¯ä¸€èŠ‚ç‚¹
        unique_nodes = list(set(self.answers_list))
        n = len(unique_nodes)
        if n == 0:
            return {}
        if n == 1:
            return {unique_nodes[0]: 1.0}
        
        node_to_idx = {node: i for i, node in enumerate(unique_nodes)}
        
        # 2. åˆå§‹åŒ–é‚»æ¥çŸ©é˜µ M
        M = np.zeros((n, n), dtype=int)
        
        for winner, loser in self.pairwise_relations:
            if winner in node_to_idx and loser in node_to_idx:
                u, v = node_to_idx[winner], node_to_idx[loser]
                M[u][v] = 1
                M[v][u] = 0 

        # 3. è®¡ç®—ä¼ é€’é—­åŒ… (Floyd-Warshall)
        Closure = M.copy()
        for k in range(n):
            for i in range(n):
                for j in range(n):
                    # å¦‚æœ i>k ä¸” k>jï¼Œåˆ™æ¨æ–­ i>j
                    Closure[i][j] = Closure[i][j] or (Closure[i][k] and Closure[k][j])
        
        # 4. è®¡ç®— Borda Count (å‡ºåº¦)
        borda_counts = Closure.sum(axis=1) # Shape: (n,)
        
        # 5. è®¡ç®—å…¨å±€åˆ†ä½æ•°åˆ†æ•° (Global Quantile Score)
        # è®ºæ–‡å…¬å¼: Qg(v) = 1 - (Rank(v) - 1) / (N - 1)
        # Rank(v) æ˜¯ 1-based (1ä»£è¡¨æœ€å¥½), N æ˜¯èŠ‚ç‚¹æ€»æ•°
        
        # å°†èŠ‚ç‚¹æŒ‰ Borda Count ä»å¤§åˆ°å°æ’åº
        # åˆ›å»º (index, borda_count) åˆ—è¡¨
        indexed_borda = list(enumerate(borda_counts))
        # æ’åºï¼šåˆ†æ•°é«˜çš„æ’å‰é¢
        indexed_borda.sort(key=lambda x: x[1], reverse=True)
        
        ebc_scores = {}
        # åˆ†é…æ’å
        # i æ˜¯ 0-based index, å¯¹åº” Rank = i + 1
        # ä½†æˆ‘ä»¬éœ€è¦å¤„ç† Borda Count ç›¸åŒçš„æƒ…å†µï¼ˆTie-breakingï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨æ’åºåçš„ç´¢å¼•
        
        for rank_idx, (original_idx, count) in enumerate(indexed_borda):
            node = unique_nodes[original_idx]
            rank = rank_idx + 1 # 1-based rank
            
            # åº”ç”¨å…¬å¼
            if n > 1:
                quantile_score = 1.0 - (rank - 1) / (n - 1)
            else:
                quantile_score = 1.0
                
            ebc_scores[node] = quantile_score

        self.ebc_global_scores = ebc_scores
        print(f"--- EBC è®¡ç®—å®Œæˆï¼Œè¦†ç›– {n} ä¸ªèŠ‚ç‚¹ (Top Node Borda: {indexed_borda[0][1]}) ---")
        return ebc_scores

    # ... (çœç•¥ optimize_experience_library åŠç›¸å…³è¾…åŠ©å‡½æ•°ï¼Œä¿æŒåŸæ ·æˆ–æŒ‰éœ€ä¿ç•™) ...
    async def optimize_experience_library(self, rag: 'AsyncFaissRAG', now_experiences: List[str]):
        """
        æ ¹æ® GRPO è®ºæ–‡çš„æ€æƒ³ï¼Œæ™ºèƒ½åœ°ä¼˜åŒ–ç»éªŒåº“ (æœ€ç»ˆç‰ˆï¼šæ‰‹åŠ¨æ„å»º Schema ä»¥ç¡®ä¿ API å…¼å®¹æ€§)ã€‚
        :param rag: ç»éªŒåº“RAGå®ä¾‹ã€‚
        :param now_experiences: æœ¬è½®è¿­ä»£ä¸­æ–°ç”Ÿæˆçš„ä¸€æ‰¹ç»éªŒã€‚
        """
        if not now_experiences:
            print("æ²¡æœ‰æ–°çš„ç»éªŒï¼Œè·³è¿‡ä¼˜åŒ–ã€‚")
            return

        print(f"\n--- å¼€å§‹ç»éªŒåº“ä¼˜åŒ–ï¼Œæ”¶åˆ° {len(now_experiences)} æ¡ç°æœ‰ç»éªŒ ---")
        from typing import List, Literal, Dict, Any
        from pydantic import BaseModel, Field
        # --- æ­¥éª¤ 1: ã€ä»ç„¶éœ€è¦ã€‘å®šä¹‰ Pydantic æ¨¡å‹ï¼Œä½†ä»…ç”¨äºã€è§£æã€‘LLM çš„è¿”å›ç»“æœ ---
        # æˆ‘ä»¬ä¸å†ä½¿ç”¨å®ƒä»¬æ¥ç”Ÿæˆ Schemaï¼Œæ‰€ä»¥å®ƒä»¬çš„å®šä¹‰ä¸ä¼šå¼•å‘é”™è¯¯ã€‚
        class ExperienceOperation(BaseModel):
            option: Literal["add", "modify", "merge", "delete"]
            experience: str = None
            modified_from_id: int = None
            merged_from_ids: List[int] = None
            delete_id: int = None

        class ExperienceUpdatePlan(BaseModel):
            think: str
            plan: List[ExperienceOperation]

        # --- æ­¥éª¤ 2: å‡†å¤‡ Prompt è¾“å…¥ (ä¿æŒä¸å˜) ---
        existing_results = await rag.search(self.query, top_k=10)
        existing_experiences_str = "\n".join([f"ID: {res['id']}, Content: {res['value']}" for res in existing_results])
        if not existing_experiences_str:
            existing_experiences_str = "æ— ç›¸å…³è¿‡å¾€ç»éªŒã€‚"
        now_experiences_str = "\n".join([f"- {s}" for s in now_experiences])
        prompt = self.prompter.OPTIMIZE_EXPERIENCE_PROMPT.format(
            existing_experiences=existing_experiences_str,
            now_experiences=now_experiences_str
        )

        # --- æ­¥éª¤ 3: ã€æ ¸å¿ƒä¿®æ”¹ã€‘æ‰‹åŠ¨å®šä¹‰ä¸€ä¸ªå®Œå…¨â€œæ‰å¹³åŒ–â€çš„ JSON Schema ---
        # è¿™ä¸ª schema æ²¡æœ‰ä»»ä½•åµŒå¥—å®šä¹‰($defs, definitions)æˆ–å¼•ç”¨($ref)ï¼Œä¿è¯äº†æœ€å¤§çš„å…¼å®¹æ€§ã€‚
        MANUAL_TOOL_SCHEMA = {
            "type": "object",
            "properties": {
                "think": {
                    "type": "string",
                    "description": "ä¼˜åŒ–å†³ç­–çš„æ€è€ƒè¿‡ç¨‹ä¸å°‘äº500å­—ã€‚"
                },
                "plan": {
                    "type": "array",
                    "description": "åŒ…å«ä¸€ç³»åˆ—æ“ä½œçš„ä¿®è®¢è®¡åˆ’ã€‚",
                    "items": {
                        "type": "object",
                        "properties": {
                            "option": {
                                "type": "string",
                                "description": "è¦æ‰§è¡Œçš„æ“ä½œç±»å‹ã€‚",
                                "enum": ["add", "modify", "merge", "delete"]
                            },
                            "experience": {
                                "type": "string",
                                "description": "å¯¹äº'add', 'modify', 'merge'æ“ä½œï¼Œè¿™æ˜¯æ–°çš„ç»éªŒå†…å®¹ã€‚"
                            },
                            "modified_from_id": {
                                "type": "integer",
                                "description": "å¯¹äº'modify'æ“ä½œï¼Œè¿™æ˜¯è¢«ä¿®æ”¹çš„æ—§ç»éªŒçš„IDã€‚"
                            },
                            "merged_from_ids": {
                                "type": "array",
                                "description": "å¯¹äº'merge'æ“ä½œï¼Œè¿™æ˜¯è¢«åˆå¹¶çš„æ—§ç»éªŒçš„IDåˆ—è¡¨ã€‚",
                                "items": {"type": "integer"}
                            },
                            "delete_id": {
                                "type": "integer",
                                "description": "å¯¹äº'delete'æ“ä½œï¼Œè¿™æ˜¯è¦åˆ é™¤çš„ç»éªŒçš„IDã€‚"
                            }
                        },
                        "required": ["option"]
                    }
                }
            },
            "required": ["think", "plan"]
        }
        
        # --- æ­¥éª¤ 4: æ„å»ºå¹¶å‘é€ API è¯·æ±‚ ---
        update_plan = None
        MAX_RETRIES = 3
    
        for attempt in range(MAX_RETRIES):
            try:
                data = copy.deepcopy(self.data_template)
                data["model"] = self.api_llm2.api_model
                data["messages"] = [{"role": "user", "content": prompt}]
                
                # æ ¹æ®æ‚¨çš„APIè¦æ±‚ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨ 'function_declarations' æˆ– 'tools'
                # æˆ‘ä»¬è¿™é‡Œä½¿ç”¨æ ‡å‡†çš„ 'tools' æ ¼å¼
                data["tools"] = [{
                    "type": "function",
                    "function": {
                        "name": "ExperienceUpdatePlan",
                        "description": "ç”¨äºä¼˜åŒ–ç»éªŒåº“çš„æ€è€ƒè¿‡ç¨‹å’Œå…·ä½“æ“ä½œè®¡åˆ’ã€‚",
                        "parameters": MANUAL_TOOL_SCHEMA  # ä½¿ç”¨æˆ‘ä»¬æ‰‹åŠ¨åˆ›å»ºçš„ã€å¹²å‡€çš„ schema
                    }
                }]
                data["tool_choice"] = {"type": "function", "function": {"name": "ExperienceUpdatePlan"}}
                data["timeout"] = 36000
                print("--- æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆä¼˜åŒ–è®¡åˆ’ (ä½¿ç”¨æ‰‹åŠ¨ Schema)... ---")
                response = await self.api_llm2.client.chat.completions.create(**data)

                # [æ–°å¢] è®°å½•tokenä½¿ç”¨
                self._record_token_usage(response)

                response_message = response.choices[0].message
                tool_calls = response_message.tool_calls

                if tool_calls:
                    function_args_str = tool_calls[0].function.arguments
                    function_args = json.loads(function_args_str)
                    # ä½¿ç”¨ Pydantic æ¨¡å‹æ¥éªŒè¯å’Œè§£æè¿”å›çš„ JSON
                    update_plan = ExperienceUpdatePlan(**function_args)
                    print("--- æˆåŠŸè§£æä¼˜åŒ–è®¡åˆ’ ---")
                else:
                    print("é”™è¯¯ï¼šLLM æœªèƒ½æŒ‰é¢„æœŸç”Ÿæˆå·¥å…·è°ƒç”¨ã€‚")

            except Exception as e:
                print(f"è°ƒç”¨LLMæˆ–è§£æä¼˜åŒ–è®¡åˆ’æ—¶å‡ºé”™ (å°è¯• {attempt + 1}/{MAX_RETRIES}): {e}")
                if attempt < MAX_RETRIES - 1:
                    print("å°†åœ¨1ç§’åé‡è¯•...")
                    await asyncio.sleep(1)
                else:
                    print("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚")

        # --- æ­¥éª¤ 5: å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œåˆ™æ‰§è¡Œä¿å®ˆç­–ç•¥ ---
        if not update_plan:
            print("æ‰€æœ‰å°è¯•å‡å¤±è´¥ã€‚é‡‡å–ä¿å®ˆç­–ç•¥ï¼šä»…æ·»åŠ æ–°ç»éªŒã€‚")
            for exp in now_experiences:
                await rag.add_document(self.query, exp)
            return

        if not update_plan or not update_plan.plan:
            print("LLMæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ä¼˜åŒ–è®¡åˆ’æˆ–è®¡åˆ’ä¸ºç©ºã€‚")
            if update_plan and update_plan.think:
                print(f"LLMçš„æ€è€ƒè¿‡ç¨‹: {update_plan.think}")
            return
        
        print(f"LLM æ€è€ƒè¿‡ç¨‹:\n{update_plan.think}\n")

        # --- æ­¥éª¤ 5: æ‰§è¡Œä¼˜åŒ–è®¡åˆ’ (æ‚¨çš„é€»è¾‘ä¿æŒä¸å˜) ---
        print(f"--- å‡†å¤‡æ‰§è¡Œ {len(update_plan.plan)} ä¸ªæ“ä½œ ---")
        # ... æ‚¨çš„ for å¾ªç¯æ‰§è¡Œé€»è¾‘ ...
            # --- æ­¥éª¤ 4: æ‰§è¡Œä¼˜åŒ–è®¡åˆ’ (ä¿æŒä¸å˜) ---
        print("æ­£åœ¨æ‰§è¡ŒLLMç”Ÿæˆçš„ç»éªŒåº“ä¼˜åŒ–è®¡åˆ’...")
        for op in update_plan.plan:
            try:
                if op.option == "add":
                    print(f"  [ADD] æ·»åŠ æ–°ç»éªŒ: {op.experience[:50]}...")
                    await rag.add_document(self.query, op.experience)
                
                elif op.option == "delete":
                    print(f"  [DELETE] åˆ é™¤ç»éªŒ ID: {op.delete_id}")
                    await rag.delete_document(int(op.delete_id))

                elif op.option == "modify":
                    print(f"  [MODIFY] ä¿®æ”¹ç»éªŒ ID: {op.modified_from_id}")
                    print(f"     â””â”€ æ–°å†…å®¹: {op.experience[:50]}...")
                    if op.experience == "":
                        print("æ–°å†…å®¹ç»éªŒä¸ºç©º...skip")
                        continue
                    await rag.delete_document(op.modified_from_id)
                    await rag.add_document(self.query, op.experience)

                elif op.option == "merge":
                    print(f"  [MERGE] åˆå¹¶ç»éªŒ IDs: {op.merged_from_ids}")
                    print(f"     â””â”€ ç”Ÿæˆæ–°ç»éªŒ: {op.experience[:50]}...")
                    if op.experience == "":
                        print("æ–°å†…å®¹ç»éªŒä¸ºç©º...skip")
                        continue
                    for id_to_delete in op.merged_from_ids:
                        await rag.delete_document(id_to_delete)
                    await rag.add_document(self.query, op.experience)
            except Exception as e:
                print(f"æ‰§è¡Œæ“ä½œ {op.option} æ—¶å¤±è´¥: {e}")
        
        print("--- ç»éªŒåº“ä¼˜åŒ–å®Œæˆ ---\n")

    async def get_prior_experience(self, rag: AsyncFaissRAG, top_k=10):
        results = await rag.search(self.query, top_k=top_k)
        if not results:
            return "æ— "
        new_experience = ""
        for result in results:
            if float(result['similarity']) < 0.9: # ç¨å¾®æ”¾å®½ä¸€ç‚¹
                continue
            new_experience += f"{str(result['id'])}. {result['value']}\n"
        return new_experience

    async def get_weak_answer(self, parent_node):
        """åŸºäºçˆ¶èŠ‚ç‚¹è¿›åŒ–Meta-Promptå¹¶ç”Ÿæˆæ–°ç­”æ¡ˆ"""
        print("æ­£åœ¨æ‰§è¡Œè¿›åŒ–æ­¥éª¤å¹¶ç”Ÿæˆæ–°ç­”æ¡ˆ...")
        data_template2 = copy.deepcopy(self.data_template)
        parent_meta_prompt = self.node_meta_prompts.get(parent_node, [self.system])[-1]
        
        # [æ–°å¢] éšæœºé€‰æ‹©æ¨¡å‹
        selected_llm, model_info = self._select_random_model()
        print(f"[DEBUG] é€‰æ‹©æ¨¡å‹: {model_info['model_name']} ({model_info.get('model_key', 'unknown_key')})")
        
        if self.use_meta_prompt:
            prior_experience = await self.get_prior_experience(self.rag)
            if parent_node is None:
                print(f"æ­£åœ¨ä»çˆ¶èŠ‚ç‚¹ '{str(parent_node)[:50]}...' çš„meta-promptè¿›åŒ–...")
                evolved_meta_prompt = self.system
            else:
                evolved_meta_prompt = parent_meta_prompt
                
        # é€šç”¨é¢†åŸŸé€»è¾‘
        if self.use_meta_prompt:
            data_template2["messages"] = [
                {"role": "user", "content":  evolved_meta_prompt + "\n" + "##å…ˆéªŒç»éªŒ##\n" + prior_experience + "\n" + self.query}]
        else:
            evolved_meta_prompt = ""
            data_template2["messages"] = [{"role": "user", "content": self.query}]
        data_template2["model"] = selected_llm.api_model
        data_template2["extra_body"] = self.extra_body
        Example_Response, thinking, completion = await self.process_controller.Generate_Response(selected_llm, data_template2, think=self.think)
        # [æ–°å¢] è®°å½•tokenä½¿ç”¨
        self._record_token_usage(completion)
        self.thinks_bank[Example_Response] = thinking
        result = Example_Response

        # [DEBUG] æ£€æŸ¥ç”Ÿæˆçš„ç»“æœ
        print(f"[DEBUG] ç”Ÿæˆçš„ç»“æœé•¿åº¦: {len(result) if result else 0}")
        print(f"[DEBUG] ç»“æœå†…å®¹é¢„è§ˆ: '{result[:50] if result else 'EMPTY'}...'")
        print(f"[DEBUG] ç»“æœæ˜¯å¦ä¸ºç©º: {not result}")
        print(f"[DEBUG] ç»“æœæ˜¯å¦ä¸ºé”™è¯¯: {result == '<|_error_|>'}")

        # [æ–°å¢] è®°å½•èŠ‚ç‚¹ä¸æ¨¡å‹çš„æ˜ å°„å…³ç³»
        if result and result != "<|_error_|>":
            self.node_model_mapping[result] = model_info
            print(f"[DEBUG] âœ… æˆåŠŸè®°å½•èŠ‚ç‚¹æ¨¡å‹æ˜ å°„: {result[:30]}... -> {model_info['model_name']}")
            print(f"[DEBUG] å½“å‰æ˜ å°„å­—å…¸å¤§å°: {len(self.node_model_mapping)}")
        else:
            print(f"[DEBUG] âŒ æœªè®°å½•æ¨¡å‹æ˜ å°„ - ç»“æœä¸ºç©ºæˆ–é”™è¯¯")
            print(f"[DEBUG] ä½†ä»ç„¶è®°å½•æ¨¡å‹ä¿¡æ¯ç”¨äºè¿½è¸ª: {model_info['model_name']}")
            # å¯¹äºç©ºç»“æœï¼Œæˆ‘ä»¬ä¹Ÿè¦è®°å½•æ¨¡å‹ä¿¡æ¯ä»¥ä¾¿è¿½è¸ª
            empty_key = f"<EMPTY_RESULT_{len(self.node_model_mapping)}>"
            self.node_model_mapping[empty_key] = model_info
            print(f"[DEBUG] ä½¿ç”¨ä¸´æ—¶é”®è®°å½•ç©ºç»“æœçš„æ¨¡å‹: {empty_key}")

        return result, evolved_meta_prompt
    
    async def step(self, parent_node):
        return await self.get_weak_answer(parent_node)

    async def _register_node_and_link_to_parent(self, child, father):
        """æ³¨å†ŒèŠ‚ç‚¹å¹¶å»ºç«‹çˆ¶å­é“¾æ¥"""
        if child not in self.answers_list:
            self.answers_list.append(child)
            self.to_explore.append(child)
            self.childs[child] = []
            self.fathers[child] = father

        if father is not None:
            if father not in self.childs:
                self.childs[father] = []
            if child not in self.childs[father]:
                self.childs[father].append(child)

    def _truncate_to_tokens(self, text: str, max_tokens: int = 10000) -> str:
        """
        å°†æ–‡æœ¬æˆªå–åˆ°æŒ‡å®šçš„tokenæ•°é‡
        """
        if not text:
            return text
            
        try:
            # ä½¿ç”¨tokenizerè¿›è¡Œç¼–ç 
            if hasattr(self.llm, 'tokenizer') and self.llm.tokenizer:
                tokens = self.llm.tokenizer.encode(text, add_special_tokens=False)
                
                # å¦‚æœè¶…è¿‡æœ€å¤§tokenæ•°ï¼Œè¿›è¡Œæˆªå–
                if len(tokens) > max_tokens:
                    truncated_tokens = tokens[:max_tokens]
                    truncated_text = self.llm.tokenizer.decode(truncated_tokens, skip_special_tokens=True)
                    print(f"æ–‡æœ¬è¢«æˆªå–: {len(tokens)} -> {len(truncated_tokens)} tokens")
                    return truncated_text
                else:
                    return text
            else:
                # å¦‚æœæ²¡æœ‰tokenizerï¼Œä½¿ç”¨å­—ç¬¦é•¿åº¦çš„è¿‘ä¼¼æ–¹æ³•
                # å¤§æ¦‚æŒ‰ç…§ä¸­æ–‡1ä¸ªå­—ç¬¦=2ä¸ªtokenï¼Œè‹±æ–‡1ä¸ªå•è¯=1.3ä¸ªtokenæ¥ä¼°ç®—
                estimated_tokens = len(text.split()) * 1.3 + len([c for c in text if ord(c) > 127]) * 2
                if estimated_tokens > max_tokens:
                    # ç²—ç•¥æˆªå–åˆ°æŒ‡å®šæ¯”ä¾‹
                    ratio = max_tokens / estimated_tokens
                    truncated_text = text[:int(len(text) * ratio)]
                    print(f"æ–‡æœ¬è¢«è¿‘ä¼¼æˆªå–: ä¼°è®¡{estimated_tokens:.0f} tokens -> ç›®æ ‡{max_tokens} tokens")
                    return truncated_text
                else:
                    return text
        except Exception as e:
            print(f"æˆªå–æ–‡æœ¬æ—¶å‘ç”Ÿé”™è¯¯: {e}, è¿”å›åŸæ–‡æœ¬")
            return text

    def _check_all_models_ready(self, min_battles=1):
        """
        æ£€æŸ¥é…ç½®ä¸­çš„æ‰€æœ‰å¯ç”¨æ¨¡å‹æ˜¯å¦éƒ½å·²å…·å¤‡æœ‰æ•ˆçš„æ•°æ®åŸºç¡€ã€‚
        
        :param min_battles: æ¯ä¸ªæ¨¡å‹è‡³å°‘éœ€è¦çš„å¯¹æˆ˜æ¬¡æ•°ï¼Œæ‰è¢«è§†ä¸º"Effective ELO"ã€‚
        :return: Boolean
        """
        # 1. è·å–æ‰€æœ‰é…ç½®ä¸­æƒé‡ > 0 çš„æ¨¡å‹Key
        active_models = [
            k for k, v in self.model_configs.items() 
            if v.get("sampling_weight", 1) > 0
        ]
        
        if not active_models:
            return False

        # 2. æ£€æŸ¥è¿™äº›æ¨¡å‹æ˜¯å¦æœ‰è¶³å¤Ÿçš„å¯¹æˆ˜æ•°æ®
        for model_key in active_models:
            stats = self.model_battle_stats.get(model_key, {"total": 0})
            if stats["total"] < min_battles:
                # åªè¦æœ‰ä¸€ä¸ªæ¨¡å‹å¯¹æˆ˜æ•°ä¸è¶³ï¼Œå°±è®¤ä¸ºæœªå‡†å¤‡å¥½ï¼Œç»§ç»­å¼ºåˆ¶éå†
                return False
        
        return True
    async def cal_reward(self, answer):
        """
        è®¡ç®—å¥–åŠ±å¹¶è¿›åŒ– Meta Prompt (Pairwise Comparison)ã€‚
        [ä¿®æ­£]ï¼šè§£æ final_score å¹¶ç¡®å®š Local Value æ‰€éœ€çš„åŸå§‹åˆ†æ•°ã€‚
        [æ–°å¢]ï¼šå¯¹è¿‡é•¿çš„å›ç­”å†…å®¹è¿›è¡Œtokenæˆªå–ã€‚
        """
        print("è®¡ç®—å¥–åŠ±ä¸è¿›åŒ– Meta Prompt ä¸­ (PPRM Logic)...")
        
        # 1. è·å–çˆ¶èŠ‚ç‚¹
        parent_answer = self.fathers.get(answer)
        if parent_answer is None:
            # æ ¹èŠ‚ç‚¹ï¼Œæ²¡æœ‰çˆ¶èŠ‚ç‚¹è¿›è¡Œæ¯”è¾ƒï¼Œç»™äºˆé»˜è®¤åˆ†æˆ–è‡ªæˆ‘è¯„ä¼°
            # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤é«˜åˆ†ï¼Œæˆ–è€…éœ€è¦å•ç‹¬çš„Self-Evaluationé€»è¾‘
            return 8.0, 8.0, "Root Node Initialized", "", False
        
        # 2. æˆªå–è¿‡é•¿çš„å›ç­”å†…å®¹åˆ°å‰10000ä¸ªtoken
        truncated_answer = self._truncate_to_tokens(answer, max_tokens=12000)
        truncated_parent_answer = self._truncate_to_tokens(parent_answer, max_tokens=12000)
            
        # 3. è·å– Prompt
        parent_system = self.node_meta_prompts.get(parent_answer, [self.system])[-1]
        current_system = self.node_meta_prompts.get(answer, [self.system])[-1]
        
        # 4. éšæœºäº¤æ¢ä½ç½® (é˜²æ­¢ä½ç½®åå·®)
        is_swapped = random.random() > 0.5
        if is_swapped:
            r1, r2 = truncated_answer, truncated_parent_answer
            s1, s2 = current_system, parent_system
        else:
            r1, r2 = truncated_parent_answer, truncated_answer
            s1, s2 = parent_system, current_system

        # 5. æ„å»º Prompt
        query = self.query
        prior_experience = await self.get_prior_experience(self.rag)
        
        class PairwiseEvaluation(BaseModel):
            """ç”¨äºå­˜å‚¨æˆå¯¹æ¯”è¾ƒè¯„ä¼°ç»“æœåŠå…ƒç³»ç»Ÿè¿›åŒ–çš„æ··åˆæ¨¡å‹"""
            specific_criteria: str = Field(description="1. ç‰¹æœ‰è¯„ä¼°æ ‡å‡†ï¼šé’ˆå¯¹å½“å‰ç”¨æˆ·é—®é¢˜å’Œéœ€æ±‚ç±»åˆ«çš„ç‰¹æœ‰è¯„ä¼°æ ‡å‡†ã€‚")
            critique: str = Field(description="2. æ‰¹è¯„ï¼šä¸€æ­¥ä¸€æ­¥æ€è€ƒï¼Œå¯¹æ‰€æä¾›çš„æŒ‡ä»¤ä»¥åŠä¸¤ä¸ªåŠ©æ‰‹çš„å›å¤ï¼Œå¯¹æ¯ä¸€æ¡ç‰¹å®šæ ‡å‡†å’Œè¯„ä¼°ç»´åº¦éƒ½è¿›è¡Œå…·ä½“ã€è¯¦ç»†çš„æ‰¹è¯„ï¼Œå¿…é¡»æ˜ç¡®æŒ‡å‡ºå“ªä¸€æ–¹æ›´å¥½ã€‚")
            weight_allocation: str = Field(description="3. æƒé‡åˆ†é…ï¼šé€šç”¨å’Œç‰¹æœ‰æ ‡å‡†çš„æƒé‡åˆ†é…ï¼Œæ€»å’Œ100%ã€‚")
            scoring_process: str = Field(description="4. æ‰“åˆ†ï¼šè®¡ç®—æ¯ä¸ªç»´åº¦çš„å¾—åˆ†åŠåŠ æƒå¹³å‡åˆ†çš„è¿‡ç¨‹ã€‚å¯¹æ¯ä¸ªè¯„ä¼°ç»´åº¦å•ç‹¬è¯„åˆ†ï¼Œè¯„åˆ†èŒƒå›´ä¸º1 åˆ° 10 åˆ†ã€‚1 åˆ†è¡¨ç¤ºå®Œå…¨ä¸ç¬¦åˆè¦æ±‚ï¼Œ10 åˆ†è¡¨ç¤ºå®Œå…¨ç¬¦åˆè¦æ±‚ã€‚è¯„åˆ†åï¼Œç»“åˆæ¯ä¸ªç»´åº¦çš„æƒé‡ã€‚")
            final_score: list[float,float] = Field(description="5. è¾“å‡ºæœ€ç»ˆå¾—åˆ†ï¼šè®¡ç®—åŠ æƒå¹³å‡å¾—åˆ†ï¼Œå¾—å‡ºæ¯ä¸ªå›ç­”çš„ç»¼åˆå¾—åˆ†ï¼Œç»¼åˆå¾—åˆ†åœ¨ 1-10 ä¹‹é—´ï¼Œæ ¼å¼å¿…é¡»ä¸º [åˆ†æ•°1,åˆ†æ•°2]ï¼Œå…¶ä¸­åˆ†æ•°1å¯¹åº”åŠ©æ‰‹1ï¼Œåˆ†æ•°2å¯¹åº”åŠ©æ‰‹2ï¼Œç»¼åˆå¾—åˆ†åœ¨ 1-10 ä¹‹é—´ã€‚")
            new_experiences: list[str] = Field(
                description="6. åŸºäºä¸Šè¿°åˆ†æç”Ÿæˆå¤šä¸ªç‹¬ç«‹ã€ä¸é‡å¤çš„ï¼Œå‡ç»ƒåœ°æ€»ç»“å‡ºæ ¸å¿ƒé—®é¢˜å’Œå…³é”®çš„æ”¹è¿›åŸåˆ™æˆ–ç»éªŒæ•™è®­ã€‚è¿™æ˜¯ä»å…·ä½“é—®é¢˜åˆ°é€šç”¨è§£å†³æ–¹æ¡ˆçš„æç‚¼ã€‚"
            )
            new_system_prompt: str = Field(description="7. ç³»ç»Ÿæç¤ºè¯è¿›åŒ–ï¼šåˆ†æèƒœå‡ºè€…çš„å…³é”®æˆåŠŸå› å­å’Œè½è´¥è€…çš„æ•™è®­ã€‚åŸºäºæ­¤åˆ†æï¼Œç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„ã€å®Œæ•´çš„ã€æ›´å¼ºçš„å¯ä»¥ç›´æ¥ä½¿ç”¨çš„System Promptã€‚")


        prompt = self.prompter.PAIRWISE_COMPARE_PROMPT.format(
            prompt=query,
            prior_experience=prior_experience,
            system_1=s1, system_2=s2,
            response_1=r1, response_2=r2,
        )

        data_template3 = copy.deepcopy(self.data_template)
        data_template3["messages"] = [{"role": "user", "content": prompt}]
        data_template3["model"] = self.api_llm.api_model

        # [æ–°å¢] æ ¹æ®æ¨¡å‹é…ç½®åŠ¨æ€è®¾ç½®é‡‡æ ·å‚æ•°
        judge_model_name = self.api_llm.api_model
        model_config = self.judge_model_configs.get(judge_model_name, self.judge_model_configs["default"])

        # åº”ç”¨é…ç½®
        data_template3["temperature"] = model_config.get("temperature", 0.9)
        data_template3["top_p"] = model_config.get("top_p", 0.9)
        data_template3["extra_body"] = model_config.get("extra_body", {})

        print(f"[Judge Model Config] ä½¿ç”¨æ¨¡å‹: {judge_model_name}")
        print(f"  - temperature: {data_template3['temperature']}")
        print(f"  - top_p: {data_template3['top_p']}")
        print(f"  - extra_body: {data_template3['extra_body']}")


        # [æ–°å¢] é‡è¯•æœºåˆ¶
        MAX_RETRIES = 3
        evaluation = None
        last_error = None

        for attempt in range(1, MAX_RETRIES + 1):
            try:
                print(f"[Judge Attempt {attempt}/{MAX_RETRIES}] å¼€å§‹è¯„æµ‹...")
                evaluation, completion = await self.process_controller.receive_data_structural(
                    self.api_llm, data_template3, struct=PairwiseEvaluation
                )
                # [æ–°å¢] è®°å½•tokenä½¿ç”¨
                self._record_token_usage(completion)

                # ### ç±»å‹æ£€æŸ¥ ###
                # å¦‚æœè¿”å›çš„æ˜¯å­—ç¬¦ä¸²ï¼Œè¯´æ˜ç»“æ„åŒ–è§£æå¤±è´¥
                if isinstance(evaluation, str):
                    print(f"[Error] è¯„æµ‹è¿”å›äº†éç»“æ„åŒ–å­—ç¬¦ä¸²ï¼Œå†…å®¹ç‰‡æ®µ: {evaluation[:50]}...")
                    last_error = "è¿”å›éç»“æ„åŒ–å­—ç¬¦ä¸²"
                    if attempt < MAX_RETRIES:
                        print(f"  âŸ³ å°†åœ¨ 1 ç§’åé‡è¯•...")
                        await asyncio.sleep(1)
                        continue
                    else:
                        print(f"  âœ— æ‰€æœ‰ {MAX_RETRIES} æ¬¡å°è¯•å‡å¤±è´¥")
                        return 0.0, 0.0, "<|_error_|>", "", is_swapped

                # æ£€æŸ¥æ˜¯å¦æ˜¯ None
                if evaluation is None:
                    print(f"[Error] è¯„æµ‹è¿”å› None")
                    last_error = "è¿”å›None"
                    if attempt < MAX_RETRIES:
                        print(f"  âŸ³ å°†åœ¨ 1 ç§’åé‡è¯•...")
                        await asyncio.sleep(1)
                        continue
                    else:
                        print(f"  âœ— æ‰€æœ‰ {MAX_RETRIES} æ¬¡å°è¯•å‡å¤±è´¥")
                        return 0.0, 0.0, "<|_error_|>", "", is_swapped

                # ---> æˆåŠŸè·å–è¯„æµ‹ç»“æœï¼Œä¿å­˜æ•°æ®å¹¶è·³å‡ºå¾ªç¯ <---
                print(f"  âœ“ è¯„æµ‹æˆåŠŸï¼ˆç¬¬ {attempt} æ¬¡å°è¯•ï¼‰")

                # è·å–å¯¹æˆ˜åŒæ–¹çš„æ¨¡å‹ä¿¡æ¯
                answer_model_info = self.node_model_mapping.get(answer, {"model_key": "unknown", "model_name": "unknown", "organization": "unknown"})
                parent_model_info = self.node_model_mapping.get(parent_answer, {"model_key": "unknown", "model_name": "unknown", "organization": "unknown"})

                # æ ¹æ®is_swappedç¡®å®šchosenå’Œrejected
                if is_swapped:
                    # answerä½œä¸ºç¬¬ä¸€ä¸ªï¼Œparent_answerä½œä¸ºç¬¬äºŒä¸ª
                    # åœ¨è¯„æµ‹ä¸­ï¼Œchosenæ˜¯è·èƒœæ–¹ï¼Œéœ€è¦æ ¹æ®åˆ†æ•°ç¡®å®š
                    if len(evaluation.final_score) >= 2:
                        score1, score2 = evaluation.final_score[0], evaluation.final_score[1]
                        if score1 > score2:
                            chosen_model_info, rejected_model_info = answer_model_info, parent_model_info
                        else:
                            chosen_model_info, rejected_model_info = parent_model_info, answer_model_info
                    else:
                        # é»˜è®¤answerä¸ºchosenï¼ˆå› ä¸ºå®ƒæ˜¯æ–°ç”Ÿæˆçš„èŠ‚ç‚¹ï¼‰
                        chosen_model_info, rejected_model_info = answer_model_info, parent_model_info
                else:
                    # parent_answerä½œä¸ºç¬¬ä¸€ä¸ªï¼Œanswerä½œä¸ºç¬¬äºŒä¸ª
                    if len(evaluation.final_score) >= 2:
                        score1, score2 = evaluation.final_score[0], evaluation.final_score[1]
                        if score1 > score2:
                            chosen_model_info, rejected_model_info = parent_model_info, answer_model_info
                        else:
                            chosen_model_info, rejected_model_info = answer_model_info, parent_model_info
                    else:
                        # é»˜è®¤answerä¸ºchosen
                        chosen_model_info, rejected_model_info = answer_model_info, parent_model_info

                self._save_judge_data(prompt, evaluation, chosen_model_info, rejected_model_info)
                print(f"  >> å·²ä¿å­˜è¯„æµ‹æ•°æ®åˆ° {self.save_dataset_path}")
                break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯

            except Exception as e:
                print(f"[Judge Attempt {attempt}/{MAX_RETRIES}] å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                last_error = str(e)

                if attempt < MAX_RETRIES:
                    print(f"  âŸ³ å°†åœ¨ 1 ç§’åé‡è¯•...")
                    await asyncio.sleep(1)
                    continue
                else:
                    print(f"  âœ— è¯„æµ‹å¤±è´¥: æ‰€æœ‰ {MAX_RETRIES} æ¬¡å°è¯•éƒ½å¤±è´¥ï¼Œæœ€åé”™è¯¯: {last_error}")
                    return 0.0, 0.0, "<|_error_|>", "", is_swapped

        # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿ evaluation æœ‰æ•ˆ
        if evaluation is None or isinstance(evaluation, str):
            print(f"[Fatal] è¯„æµ‹æœ€ç»ˆå¤±è´¥: {last_error}")
            return 0.0, 0.0, "<|_error_|>", "", is_swapped

        # 5. è§£æåˆ†æ•°
        scores = evaluation.final_score
        if len(scores) < 2:
            scores = [0.0, 0.0]
            
        score1, score2 = scores[0], scores[1]
        
        # è¿˜åŸåˆ†æ•°å½’å±
        if is_swapped:
            child_score = score1
            parent_score = score2
        else:
            child_score = score2
            parent_score = score1
            
        await self.optimize_experience_library(self.rag, evaluation.new_experiences)
        return child_score, parent_score, evaluation.critique, evaluation.new_system_prompt, is_swapped


    async def sampling_reward(self, answer):
        """
        [æ ¸å¿ƒä¿®æ”¹]ï¼šèåˆ Local Value (PPRM Bradley-Terry) å’Œ Global Value (EBC)ã€‚
        """
        if answer not in self.to_explore_reward:
            self.to_explore_reward[answer] = []
        if answer not in self.evaluations_bank:
            self.evaluations_bank[answer] = []
        if answer not in self.node_meta_prompts:
            self.node_meta_prompts[answer] = []

        # 1. è°ƒç”¨ PPRM è·å–åŸå§‹åˆ†æ•°
        child_score, parent_score, judge_text, new_prompt, is_swapped = await self.cal_reward(answer)
        
        if judge_text == "<|_error_|>":
            return "<|_error_|>", 0.0

        if judge_text == "Root Node Initialized":
            # [æ ¹èŠ‚ç‚¹ç‰¹æ®Šå¤„ç†é€»è¾‘]
            q_global = 1.0 
            self.ebc_global_scores[answer] = q_global
            q_local = 0.5 
            self.local_values[answer] = q_local
            
            quality_score_norm = self.ebc_alpha * q_global + (1 - self.ebc_alpha) * q_local
            diversity_score_norm = 1.0 # æ ¹èŠ‚ç‚¹å¤šæ ·æ€§è®¾ä¸º1
            
            final_reward = quality_score_norm * self.max_reward
            if self.use_diversity_fusion:
                 final_reward = final_reward * diversity_score_norm

            print(f"--> [Root Node] Init Reward: {final_reward:.4f}")
            
            # [å…³é”®ä¿®å¤ç‚¹]ï¼šå¿…é¡»åœ¨è¿™é‡Œå­˜å…¥ evaluations_bankï¼Œå¦åˆ™ process_results ä¼šæŠ¥é”™
            self.evaluations_bank[answer].append({
                "final_reward": final_reward,
                "quality_score": quality_score_norm,
                "diversity_score": diversity_score_norm,
                "judge": "Root Init",
                "is_fused": self.use_diversity_fusion
            })
            
            self.to_explore_reward[answer].append(final_reward)
            
            return "Root", final_reward

        # 2. è®¡ç®—å±€éƒ¨ä»·å€¼ (Local Value) - Bradley-Terry Proxy
        # ä½¿ç”¨ Softmax å°†åˆ†æ•°å·®è½¬æ¢ä¸ºæ¦‚ç‡
        # Q_l = exp(S_child) / (exp(S_child) + exp(S_parent))
        try:
            # ç¼©æ”¾åˆ†æ•°ä»¥é¿å…æº¢å‡ºï¼Œå‡è®¾åˆ†æ•° 1-10ï¼Œå¯ä»¥ç›´æ¥ç”¨
            exp_child = math.exp(child_score)
            exp_parent = math.exp(parent_score)
            q_local = exp_child / (exp_child + exp_parent)
        except OverflowError:
            q_local = 1.0 if child_score > parent_score else 0.0

        self.local_values[answer] = q_local
        print(f"å±€éƒ¨ä»·å€¼ (Bradley-Terry): {q_local:.4f} (Child: {child_score}, Parent: {parent_score})")

        # 3. æ›´æ–° EBC å…³ç³» (ç”¨äºè®¡ç®— Global Value)
        parent_node = self.fathers.get(answer)
        margin = 0.0 # è®¾å®šèƒœè´Ÿé˜ˆå€¼
        if child_score > parent_score + margin:
            self.pairwise_relations.append((answer, parent_node))
            print("EBC Relation: Child > Parent")
        elif parent_score > child_score + margin:
            self.pairwise_relations.append((parent_node, answer))
            print("EBC Relation: Parent > Child")
        
        # 4. é‡æ–°è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„ Global Value (EBC)
        # æ³¨æ„ï¼šåœ¨å¤§å‹æ ‘ä¸­è¿™å¯èƒ½è€—æ—¶ï¼Œä½†åœ¨ <100 èŠ‚ç‚¹çš„æ ‘ä¸­å¾ˆå¿«
        self.calculate_ebc_scores()
        q_global = self.ebc_global_scores.get(answer, 0.5) # é»˜è®¤ä¸ºä¸­ä½æ•°
        # [æŒ‡æ ‡ A] çº¯è´¨é‡åˆ†æ•° (å½’ä¸€åŒ– 0~1)
        # Quality = alpha * Qg + (1-alpha) * Ql
        quality_score_norm = self.ebc_alpha * q_global + (1 - self.ebc_alpha) * q_local
        # --- [æ–°å¢] Darling è®ºæ–‡æ ¸å¿ƒï¼šè®¡ç®—å¤šæ ·æ€§ç³»æ•° ---
        # è®¡ç®—å½“å‰å›ç­”ç›¸å¯¹äºå†å²å›ç­”çš„å¤šæ ·æ€§ (0.0 ~ 1.0)
        diversity_score_norm = await self._calculate_semantic_diversity(answer)
        print(f"Diversity Score (semantic): {diversity_score_norm:.4f}")
        # [å†³ç­–] æ˜¯å¦èåˆ
        if self.use_diversity_fusion:
            # èåˆæ¨¡å¼ï¼šDarling ä¹˜æ³•å…¬å¼
            # Final = Quality * Diversity * Max_Reward
            final_reward = quality_score_norm * diversity_score_norm * self.max_reward * 10
            print(f"--> [Fusion ON] Final Reward: {final_reward:.4f}")
        else:
            # ç‹¬ç«‹æ¨¡å¼ï¼šä»…ä½¿ç”¨è´¨é‡åˆ†ä½œä¸ºå¥–åŠ±
            # Final = Quality * Max_Reward
            final_reward = quality_score_norm * self.max_reward
            print(f"--> [Fusion OFF] Final Reward: {final_reward:.4f} (Diversity ignored in UCB)")
        
        print(f"Final Reward: {final_reward:.4f} (Qg: {q_global:.4f}, Ql: {q_local:.4f})")

        # 6. å­˜å‚¨ä¸æ›´æ–°
        self.to_explore_reward[answer].append(final_reward)
        #self.evaluations_bank[answer].append({"reward": final_reward, "judge": judge_text})
        self.evaluations_bank[answer].append({
            "final_reward": final_reward,    # å®é™…ç”¨äº UCB çš„åˆ†
            "quality_score": quality_score_norm, # ç‹¬ç«‹çš„è´¨é‡æŒ‡æ ‡
            "diversity_score": diversity_score_norm, # ç‹¬ç«‹çš„å¤šæ ·æ€§æŒ‡æ ‡
            "judge": judge_text,
            "is_fused": self.use_diversity_fusion
        })
        # å­˜å‚¨è¿›åŒ–åçš„ Prompt (å¦‚æœæœ‰)
        if new_prompt:
            self.node_meta_prompts[answer].append(new_prompt)
            self.evolved_meta_prompt = new_prompt
        else:
            # å¦‚æœæ²¡ç”Ÿæˆï¼Œæ²¿ç”¨çˆ¶èŠ‚ç‚¹çš„
             self.node_meta_prompts[answer].append(self.node_meta_prompts.get(answer, [""])[0])

        return judge_text, final_reward
    
    async def _calculate_semantic_diversity(self, current_node: str):
        if not self.answers_list:
            return 1.0
            
        total_similarity = 0.0
        count = 0
        
        for other_node in self.answers_list:
            if other_node == current_node: continue
            truncated_current_node = self._truncate_to_tokens(current_node, max_tokens=10000)
            truncated_other_node = self._truncate_to_tokens(other_node, max_tokens=10000)
            # ä½¿ç”¨ RAG çš„ calculate_similarity
            sim = await self.rag.calculate_similarity(truncated_current_node, truncated_other_node)
            total_similarity += sim
            count += 1
            
        if count == 0: return 1.0
        
        avg_similarity = total_similarity / count
        # è·ç¦» = 1 - ç›¸ä¼¼åº¦
        diversity = 1.0 - avg_similarity 
        return max(0.0, diversity)

    async def update_ucb(self, C: float = 1.4, leaf_bonus: float = 1e-6):
        """
        æ›´æ–° UCB å€¼ã€‚
        [æ ¸å¿ƒè¿˜åŸ]: å®ç°äº†  Em-Mcts è®ºæ–‡ Section 2.2 çš„ Backpropagation phaseã€‚
        å…¬å¼: Q(s_i) = (1 - gamma)Q(s_i) + gamma * Q(s')
        """
        # [æ–°å¢] è®°å½•UCBæ›´æ–°å¼€å§‹
        self._record_operation("ucb_update_start", {
            "iteration": self.iter,
            "node_count": len(self.to_explore),
            "C": C,
            "gamma": self.gamma
        })
        
        # 1. é‡æ–°è®¡ç®—ä¸€æ¬¡å…¨å±€ EBCï¼Œç¡®ä¿å›¾ç»“æ„æ˜¯æœ€æ–°çš„
        self.calculate_ebc_scores()
        
        # åˆå§‹åŒ– Q_values å­˜å‚¨ç»“æ„ (å¦‚æœè¿˜æ²¡æœ‰çš„è¯)
        if not hasattr(self, 'Q_values'):
            self.Q_values = {}

        # --- é˜¶æ®µ 1: è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„åŸºç¡€è¯„ä¼°å€¼ (Evaluation Phase) ---
        # è¿™ä¸€æ­¥å¯¹åº”è®ºæ–‡ä¸­çš„ Evaluation: Q(s') = alpha * Qg + (1-alpha) * Ql
        # æˆ‘ä»¬å…ˆè®¡ç®—å‡ºæ¯ä¸ªèŠ‚ç‚¹å½“ä¸‹çš„"é™æ€"ä»·å€¼
        
        # é¢„è®¡ç®—æœ€å¤§åŸå§‹å¥–åŠ±ç”¨äºå½’ä¸€åŒ– (é˜²æ­¢é™¤é›¶)
        all_rewards = [np.mean(r) for r in self.to_explore_reward.values() if r]
        max_raw = max(all_rewards) if all_rewards else 1.0
        if max_raw == 0: max_raw = 1.0

        current_iter_q_estimates = {}

        for node in self.to_explore:
            # è·å–è¯„åˆ†ç»„ä»¶
            q_g = self.ebc_global_scores.get(node, 0.0) # Global Value (EBC)
            q_l = self.local_values.get(node, 0.5)      # Local Value (Bradley-Terry)
            
            # åŠ¨æ€æ··åˆåˆ†æ•° (å½’ä¸€åŒ–çŠ¶æ€ [0,1])
            r_c_norm = self.ebc_alpha * q_g + (1 - self.ebc_alpha) * q_l
            
            # è¿˜åŸåˆ°åŸå§‹å¥–åŠ±é‡çº§ (å‡è®¾ max_reward=10)
            r_c = r_c_norm * 10.0 
            
            # æ›´æ–°/åˆå§‹åŒ–è¯¥èŠ‚ç‚¹çš„ Q å€¼
            # æ³¨æ„ï¼šå¦‚æœæ˜¯æ–°èŠ‚ç‚¹ï¼Œç›´æ¥ä½¿ç”¨è®¡ç®—å€¼ï¼›å¦‚æœæ˜¯è€èŠ‚ç‚¹ï¼Œè¿™é‡Œå…ˆä½œä¸ºåŸºå‡†
            if node not in self.Q_values:
                self.Q_values[node] = r_c
            
            # æš‚å­˜ä¸€ä¸‹å½“å‰çš„ä¼°å€¼ï¼Œç”¨äºè°ƒè¯•æˆ–é€»è¾‘åˆ¤æ–­
            current_iter_q_estimates[node] = r_c

        # --- é˜¶æ®µ 2: åå‘ä¼ æ’­ (Backpropagation Phase) [æ ¸å¿ƒè¿˜åŸ] ---
        # è®ºæ–‡å…¬å¼: Q(si) = (1 - gamma)Q(si) + gamma * Q(s')
        # æˆ‘ä»¬ä½¿ç”¨å€’åºéå† (Reversed) æ¥æ¨¡æ‹Ÿä»å­èŠ‚ç‚¹ (Latest/Leaf) å‘çˆ¶èŠ‚ç‚¹ (Root) çš„ä¼ æ’­
        # è¿™æ ·ç¡®ä¿æ·±å±‚çš„ä¼˜å¼‚è¡¨ç°èƒ½ä¼ é€’å›ä¸Šå±‚èŠ‚ç‚¹
        
        print(f"\n--- æ‰§è¡Œåå‘ä¼ æ’­ (Gamma: {self.gamma}) ---")
        # å‡è®¾ answers_list æ˜¯æŒ‰ç”Ÿæˆé¡ºåºæ’åˆ—çš„ï¼Œå€’åºå³ä»æœ€æ–°çš„å­èŠ‚ç‚¹å¼€å§‹
        backprop_operations = []
        for node in reversed(self.answers_list):
            parent = self.fathers.get(node)
            
            # å¦‚æœæœ‰çˆ¶èŠ‚ç‚¹ï¼Œä¸”çˆ¶èŠ‚ç‚¹ä¹Ÿåœ¨æˆ‘ä»¬çš„æ¢ç´¢åˆ—è¡¨ä¸­
            if parent and parent in self.Q_values:
                q_child = self.Q_values[node]
                q_parent_old = self.Q_values[parent]
                
                # [æ ¸å¿ƒå…¬å¼åº”ç”¨]
                # çˆ¶èŠ‚ç‚¹çš„ä»·å€¼ = (1 - gamma) * åŸä»·å€¼ + gamma * å­èŠ‚ç‚¹ä»·å€¼
                q_parent_new = (1 - self.gamma) * q_parent_old + self.gamma * q_child
                
                self.Q_values[parent] = q_parent_new
                
                # è®°å½•æ˜¾è‘—å˜åŒ–
                if abs(q_parent_new - q_parent_old) > 0.1:
                    backprop_operations.append({
                        "child": node[:20] + "...",
                        "parent": parent[:20] + "...",
                        "old_q": q_parent_old,
                        "new_q": q_parent_new,
                        "change": q_parent_new - q_parent_old
                    })
                    print(f"Propagated: {node[:10]}... -> {parent[:10]}... | Parent Q: {q_parent_old:.2f} -> {q_parent_new:.2f}")

        # --- é˜¶æ®µ 3: è®¡ç®— UCB (Selection Phase Preparation) ---
        # ä½¿ç”¨æ›´æ–°åçš„ self.Q_values è®¡ç®— UCB
        
        debug_stats = []
        for node in self.to_explore:
            # ä½¿ç”¨åå‘ä¼ æ’­æ›´æ–°åçš„ Q å€¼
            Q_val = self.Q_values.get(node, 0.0)
            
            # è·å–è®¿é—®æ¬¡æ•° N_c
            rewards_list = self.to_explore_reward.get(node, [])
            N_c = len(rewards_list)
            
            # è·å–çˆ¶èŠ‚ç‚¹è®¿é—®æ¬¡æ•° N_n
            parent = self.fathers.get(node)
            if parent:
                parent_rewards = self.to_explore_reward.get(parent, [])
                N_n = len(parent_rewards)
                if N_n == 0: N_n = 1
            else:
                N_n = self.iter 

            # UCB å…¬å¼è®¡ç®—
            if N_c == 0:
                 ucb_value = Q_val + 0.1 # æœªæ¢ç´¢åŠ æˆ
            else:
                 ucb_value = Q_val + C * math.sqrt(math.log(N_n + 1) / (N_c + 1e-5))
            
            self.ucb_bank[node] = ucb_value
            
            q_g = self.ebc_global_scores.get(node, 0.0)
            q_l = self.local_values.get(node, 0.5)
            debug_stats.append((node, ucb_value, Q_val, q_g, q_l, N_c))

        # [æ–°å¢] è®°å½•UCBæ›´æ–°å®Œæˆ
        self._record_operation("ucb_update_complete", {
            "iteration": self.iter,
            "total_ucb_nodes": len(self.ucb_bank),
            "backprop_changes": len(backprop_operations),
            "avg_ucb": sum(self.ucb_bank.values()) / len(self.ucb_bank) if self.ucb_bank else 0
        })

        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        debug_stats.sort(key=lambda x: x[1], reverse=True)
        print(f"\nTop 5 UCB Nodes (Iter {self.iter}) [After Backprop]:")
        print(f"{'Node':<20} | {'UCB':<8} | {'Q(Prop)':<8} | {'Qg':<6} | {'Ql':<6} | {'Visits':<6} | {'Model'}")
        print("-" * 100)
        for d in debug_stats[:5]:
            # d[0]ç°åœ¨æ˜¯å®Œæ•´çš„èŠ‚ç‚¹æ–‡æœ¬ï¼Œéœ€è¦æˆªæ–­æ˜¾ç¤º
            node_str = d[0][:20].replace('\n', ' ')
            # è·å–èŠ‚ç‚¹å¯¹åº”çš„æ¨¡å‹ä¿¡æ¯ï¼Œä½¿ç”¨å®Œæ•´èŠ‚ç‚¹æ–‡æœ¬ä½œä¸ºé”®
            model_info = self.node_model_mapping.get(d[0], {"model_name": "unknown"})
            model_name = model_info.get("model_name", "unknown")
            
            # [DEBUG] å¦‚æœæ¨¡å‹æ˜¯unknownï¼Œå°è¯•æŸ¥æ‰¾ç©ºç»“æœçš„æ¨¡å‹æ˜ å°„
            if model_name == "unknown":
                print(f"[DEBUG] æœªæ‰¾åˆ°èŠ‚ç‚¹ '{d[0][:30] if d[0] else 'EMPTY_STRING'}...' çš„æ¨¡å‹æ˜ å°„")
                print(f"[DEBUG] èŠ‚ç‚¹é•¿åº¦: {len(d[0])}")
                print(f"[DEBUG] èŠ‚ç‚¹repr: {repr(d[0][:50])}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºç»“æœçš„ä¸´æ—¶é”®
                empty_keys = [k for k in self.node_model_mapping.keys() if k.startswith("<EMPTY_RESULT_")]
                if empty_keys:
                    print(f"[DEBUG] å‘ç°ç©ºç»“æœä¸´æ—¶é”®: {empty_keys}")
                    # ä½¿ç”¨æœ€æ–°çš„ç©ºç»“æœé”®
                    latest_empty_key = max(empty_keys, key=lambda x: int(x.split('_')[-1].rstrip('>')))
                    empty_model_info = self.node_model_mapping[latest_empty_key]
                    model_name = f"{empty_model_info.get('model_name', 'unknown')} (EMPTY)"
                    print(f"[DEBUG] ç©ºç»“æœå¯¹åº”æ¨¡å‹: {model_name}")
                else:
                    print(f"[DEBUG] æ˜ å°„å­—å…¸ä¸­çš„æ‰€æœ‰é”®: {list(self.node_model_mapping.keys())[:5]}")
                    print(f"[DEBUG] èŠ‚ç‚¹æ˜¯å¦åœ¨æ˜ å°„ä¸­: {d[0] in self.node_model_mapping}")
            
            print(f"{node_str:<20} | {d[1]:<8.2f} | {d[2]:<8.2f} | {d[3]:<6.2f} | {d[4]:<6.2f} | {d[5]:<6} | {model_name}")

        if self.enable_state_tracking:
            self._capture_state_snapshot()

    async def filter_mature_node(self, max_expand=2):
        filtered_to_explore = [
            node for node in self.to_explore
            if len(self.childs.get(node, [])) < max_expand
        ]
        return filtered_to_explore

    def get_best_explore_from_ucb(self, to_explore):
        best_node = None
        highest_ucb = float('-inf')
        for node in to_explore:
            ucb_value = self.ucb_bank.get(node, 0)
            if ucb_value > highest_ucb:
                highest_ucb = ucb_value
                best_node = node
        return best_node
    
    async def system_create_expert_algorithm(self,choose_llm: LLM_Core, question,roleplay=False):
        prompt = self.prompter.Create_Expert_Prompt.format(question=question)
        data_template2 = copy.deepcopy(self.data_template)
        data_template2["messages"] = [
                                {"role": "user", "content": prompt}]
        data_template2["model"] = choose_llm.api_model
        L_instruction = await self.process_controller.receive_data(choose_llm,data_template2)
        if "[è§’è‰²æè¿°]ï¼š" in L_instruction:
            L_instruction = L_instruction.split("[è§’è‰²æè¿°]ï¼š")[-1]
        return L_instruction
    
    def draw_tree_pyvis(self, filename="tree.html"):
        """ä½¿ç”¨pyvisç»˜åˆ¶æ ‘ç»“æ„å¹¶ä¿å­˜ä¸ºHTMLæ–‡ä»¶ï¼Œå¹¶æ ‡è®°èŠ‚ç‚¹äº§ç”Ÿçš„è¿­ä»£æ¬¡æ•°å’Œå¹³å‡åˆ†ï¼Œé¢œè‰²æ ¹æ®åˆ†å€¼å˜åŒ–"""
        net = Network(directed=True, width="100%", height="600px", bgcolor="#222222", font_color="white")

        avg_reward = {node: np.mean(rewards) for node, rewards in self.to_explore_reward.items() if rewards}
        plottable_nodes = {node: score for node, score in avg_reward.items() if not np.isnan(score)}
        all_scores = list(plottable_nodes.values())
        min_score = min(all_scores) if all_scores else 0
        max_score = max(all_scores) if all_scores else 1

        node_iterations = {answer: i for i, answer in enumerate(self.answers_list)}

        # --- 1. ç»˜åˆ¶èŠ‚ç‚¹ (ä¿æŒåŸæœ‰é€»è¾‘å’Œæ ·å¼ä¸å˜) ---
        for node, score in plottable_nodes.items():
            score_str = f"{score:.2f}"
            
            # è¯†åˆ«æ ¹èŠ‚ç‚¹
            is_root = self.fathers.get(node) is None

            if is_root:
                label = f"ROOT (Iter {node_iterations.get(node, 0)})"
                color = "#33FF57"
            else:
                iteration = node_iterations.get(node, "?")
                short_text = node[:30] + "..." if len(node) > 30 else node
                label = f"{short_text}\nIter {iteration}, Score: {score_str}"
                
                normalized_score = (score - min_score) / (max_score - min_score) if max_score != min_score else 0.5
                if normalized_score < 0.5:
                    r, g, b = 255, int(255 * (normalized_score * 2)), 0
                else:
                    r, g, b = int(255 * (1 - (normalized_score - 0.5) * 2)), 255, 0
                color = f"#{r:02x}{g:02x}{b:02x}"
            
            # åœ¨æ ‡é¢˜ä¸­æ˜¾ç¤ºå¯¹åº”çš„meta-prompt
            node_meta = self.node_meta_prompts.get(node, "N/A")
            # æ³¨æ„ï¼šè¿™é‡Œå–æœ€åä¸€æ¡ meta promptï¼Œå¦‚æœæ˜¯åˆ—è¡¨
            if isinstance(node_meta, list) and node_meta:
                 node_meta_str = node_meta[-1]
            else:
                 node_meta_str = str(node_meta)

            title = f"Full text: {node}\nAverage score: {score_str}\n---\nMeta-Prompt: {node_meta_str}"
            net.add_node(node, label=label, color=color, title=title)

        for node, father in self.fathers.items():
            if father and father in net.get_nodes() and node in net.get_nodes():
                net.add_edge(father, node, color="#FF5733")

        net.force_atlas_2based()
        net.show(filename, notebook=False)
        print(f"æ ‘ç»“æ„å·²ä¿å­˜åˆ° {filename}")

    async def main_loop(self, inputs):
        """ä¸»å¾ªç¯"""
        inputs_copy = copy.deepcopy(inputs)
        print("max iter:", self.max_iter)
        
        # [æ–°å¢] è®°å½•ä¸»å¾ªç¯å¼€å§‹
        self._record_operation("main_loop_start", {
            "inputs": inputs_copy,
            "max_iter": self.max_iter,
            "enable_state_tracking": self.enable_state_tracking
        })
        
        if "category" in inputs_copy: self.class_tag = inputs_copy.get("category", "")
        if "class_tag" in inputs_copy: self.class_tag = inputs_copy.get("class_tag", "")
        self.context = inputs_copy.get("context", "")
        self.system, self.query = inputs_copy["prompt"][0]["content"], inputs_copy["prompt"][1]["content"]
        if self.use_expert_prompt == True:
            choose_llm = self.api_llm2
            L_system = await self.system_create_expert_algorithm(choose_llm, question=self.query)
            print("L_system:",L_system)
            self.system = L_system
        self.default_system = self.system
        self.domain = inputs_copy.get("domain", "é€šç”¨")
        self.uid = inputs_copy.get("uid","")

        # --- 1. åˆå§‹åŒ– ---
        print("--- åˆå§‹åŒ–é˜¶æ®µ ---")
        
        # [æ–°å¢] åœ¨å¼€å§‹ä¹‹å‰å…ˆæ›´æ–°ä¸€æ¬¡ELOè¯„åˆ†å’Œæƒé‡
        self.update_elo_ratings()
        
        # [æ–°å¢] è®°å½•åˆå§‹åŒ–å®Œæˆ
        self._record_operation("initialization_complete", {
            "domain": self.domain,
            "query": self.query[:100] + "..." if len(self.query) > 100 else self.query,
            "system": self.system[:100] + "..." if len(self.system) > 100 else self.system
        })
        
        first_answer, evolved_meta_for_first = await self.step(parent_node=None)
        if "<|_error_|>" in first_answer: return "<|_error_|>"
        
        await self._register_node_and_link_to_parent(first_answer, None)
        self.node_meta_prompts[first_answer] = [evolved_meta_for_first]
        
        # åˆå§‹è¯„ä¼°
        judge, initial_reward = await self.sampling_reward(first_answer)
        if judge == "<|_error_|>": return "<|_error_|>"
        await self.update_ucb(C=1.4)
        MAX_ITER_RETRIES = 3
        # --- 2. è¿­ä»£æœç´¢ ---
        for i in range(self.max_iter):
            print(f'\n--- è¿­ä»£ {i + 1} / {self.max_iter} ---')
            self.iter = i + 1
            
            # [æ–°å¢] è®°å½•è¿­ä»£å¼€å§‹
            self._record_operation("iteration_start", {
                "iteration": self.iter,
                "total_nodes": len(self.answers_list),
                "explore_nodes": len(self.to_explore)
            })
            
            # [æ–°å¢] å¼€å§‹ç¬¬ä¸€ä¸ªrollout
            self.update_elo_ratings()
            filtered_to_explore = await self.filter_mature_node(max_expand=self.max_expand)
            node_to_expand = self.get_best_explore_from_ucb(filtered_to_explore)

            if not node_to_expand: 
                print("æ²¡æœ‰å¯æ¢ç´¢çš„èŠ‚ç‚¹ï¼Œç»“æŸå¾ªç¯ã€‚")
                # [æ–°å¢] è®°å½•æå‰ç»“æŸ
                self._record_operation("early_termination", {
                    "reason": "no_expandable_nodes",
                    "iteration": self.iter,
                    "total_iterations": self.max_iter
                })
                break
            
            print(f"é€‰æ‹©èŠ‚ç‚¹è¿›è¡Œæ‰©å±•: {str(node_to_expand)[:50]}...")
            
            # [æ–°å¢] è®°å½•èŠ‚ç‚¹é€‰æ‹©
            self._record_operation("node_selection", {
                "selected_node": str(node_to_expand)[:100] + "..." if len(str(node_to_expand)) > 100 else str(node_to_expand),
                "ucb_value": self.ucb_bank.get(node_to_expand, 0),
                "iteration": self.iter
            })
            
            new_answer, new_meta_prompt = await self.step(node_to_expand)

            if "<|_error_|>" in new_answer: 
                # [æ–°å¢] è®°å½•é”™è¯¯
                self._record_operation("generation_error", {
                    "parent_node": str(node_to_expand)[:100] + "..." if len(str(node_to_expand)) > 100 else str(node_to_expand),
                    "iteration": self.iter
                })
                continue
            if new_answer == node_to_expand: 
                self.max_expand += 1
                # [æ–°å¢] è®°å½•é‡å¤ç­”æ¡ˆ
                self._record_operation("duplicate_answer", {
                    "parent_node": str(node_to_expand)[:100] + "..." if len(str(node_to_expand)) > 100 else str(node_to_expand),
                    "iteration": self.iter,
                    "new_max_expand": self.max_expand
                })
                continue

            # æ³¨å†Œä¸é“¾æ¥
            await self._register_node_and_link_to_parent(new_answer, node_to_expand)
            if new_answer not in self.node_meta_prompts: self.node_meta_prompts[new_answer] = []
            self.node_meta_prompts[new_answer].append(new_meta_prompt)

            # è¯„ä¼°ä¸åå‘ä¼ æ’­
            judge, reward = await self.sampling_reward(new_answer)
            if judge == "<|_error_|>": return "<|_error_|>"
            
            # æ›´æ–° UCB
            await self.update_ucb(C=1.4)
            
            # [æ–°å¢] è®°å½•è¿­ä»£å®Œæˆ
            self._record_operation("iteration_complete", {
                "iteration": self.iter,
                "new_node": str(new_answer)[:100] + "..." if len(str(new_answer)) > 100 else str(new_answer),
                "reward": reward,
                "total_nodes": len(self.answers_list)
            })
            
            # [æ–°å¢] è‡ªåŠ¨ä¿å­˜æ£€æŸ¥
            if self.enable_state_tracking and self.auto_save_interval > 0 and self.iter % self.auto_save_interval == 0:
                print(f"[è‡ªåŠ¨ä¿å­˜] è¿­ä»£ {self.iter} - ä¿å­˜çŠ¶æ€...")
                self.save_state()
                if self.enable_visualization:
                    self.create_interactive_visualization()
            
            # path = os.path.join(f"tree_iter_{i + 1}.html")
            # self.draw_tree_pyvis(path)
            
        # [æ–°å¢] è®°å½•ä¸»å¾ªç¯å®Œæˆ
        self._record_operation("main_loop_complete", {
            "total_iterations": self.iter,
            "total_nodes": len(self.answers_list),
            "final_ucb_values": len(self.ucb_bank)
        })
        
        # [æ–°å¢] æœ€ç»ˆä¿å­˜çŠ¶æ€å’Œå¯è§†åŒ–
        if self.enable_state_tracking:
            print("[æœ€ç»ˆä¿å­˜] ä¿å­˜å®Œæ•´çŠ¶æ€å’Œå¯è§†åŒ–...")
            self.save_state()
            if self.enable_visualization:
                self.create_interactive_visualization()
        
        return await self.process_results(inputs_copy)
    
    def dialog_length(self, node):
        dialog_list = self.tools.parse_fields(node)
        return len(dialog_list)

    async def process_results(self, inputs, alpha: float = 0.9, rho: float = 0.1) -> List[Dict[str, any]]:
        """
        [å®Œæ•´ç‰ˆ] å¤„ç†æœ€ç»ˆç»“æœã€‚
        1. æ±‡æ€»æ‰€æœ‰èŠ‚ç‚¹çš„ Local Value å’Œ Global Valueã€‚
        2. è®¡ç®—æœ€ç»ˆæ··åˆå¾—åˆ†ã€‚
        3. æå– Best (Chosen) å’Œ Worst (Rejected)ã€‚
        4. ç»„è£…åŒ…å« Chain-of-Thought å’Œ Meta Prompt çš„å®Œæ•´æ•°æ®å­—å…¸ã€‚
        """
        try:
            input_dict = copy.deepcopy(inputs)
            
            # 1. è¿‡æ»¤æ— æ•ˆèŠ‚ç‚¹ (å¿…é¡»æœ‰å¥–åŠ±è®°å½•)
            valid_nodes = [n for n in self.to_explore_reward if self.to_explore_reward[n]]
            if not valid_nodes:
                print("æ²¡æœ‰æœ‰æ•ˆçš„å¥–åŠ±æ•°æ®ï¼Œæ— æ³•é€‰æ‹©ç»“æœã€‚")
                return []

            # 2. å‡†å¤‡è¯„åˆ†æ•°æ®
            # é‡æ–°è®¡ç®—ä¸€æ¬¡ EBC ä»¥é˜²ä¸‡ä¸€
            q_g_scores_raw = self.calculate_ebc_scores()
            
            # ç»Ÿè®¡åŸå§‹å¥–åŠ±å‡å€¼ (ç”¨äºè®°å½•æ—¥å¿—ï¼Œä¸å‚ä¸æœ€ç»ˆæ’åº)
            raw_rewards_mean = {n: np.mean(self.to_explore_reward[n]) for n in valid_nodes}
            
            final_scores = {}
            debug_info = []
                
            
            for node in valid_nodes:
                if self.domain == "å¿ƒç†" and rho > 0:
                    # è·å–å½“å‰èŠ‚ç‚¹é•¿åº¦
                    length = self.dialog_length(node)
                    
                    # è·å–æ‰€æœ‰ valid_nodes çš„é•¿åº¦ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
                    all_lengths = [self.dialog_length(n) for n in valid_nodes]
                    max_len = max(all_lengths)
                    min_len = min(all_lengths)
                # --- A. è·å– Local Score (Ql) ---
                # ä¼˜å…ˆä½¿ç”¨ sampling_reward ä¸­è®¡ç®—å¥½çš„ Bradley-Terry æ¦‚ç‡
                q_local = self.local_values.get(node)
                # å¦‚æœç¼ºå¤± (ç†è®ºä¸Šä¸åº”å‘ç”Ÿ)ï¼Œä½¿ç”¨ Sigmoid å¯¹åŸå§‹åˆ†å½’ä¸€åŒ–ä½œä¸ºå…œåº•
                if q_local is None:
                    raw_val = raw_rewards_mean[node]
                    # ç®€å•çš„ Sigmoid æ˜ å°„: 1 / (1 + exp(-(x - 5))) å‡è®¾å‡åˆ†5åˆ†
                    q_local = 1 / (1 + np.exp(-(raw_val - 5.0)))

                # --- B. è·å– Global Score (Qg) ---
                q_global = q_g_scores_raw.get(node, 0.0)
                
                # --- C. èåˆ Q(s) ---
                # alpha æ§åˆ¶ EBC å…¨å±€æ’åçš„æƒé‡
                final_score = alpha * q_global + (1 - alpha) * q_local

                if self.domain == "å¿ƒç†":
                    # çº¿æ€§å½’ä¸€åŒ–åˆ° [0, 1]
                    # é¿å…é™¤é›¶ï¼šå¦‚æœæ‰€æœ‰é•¿åº¦ç›¸åŒï¼Œåˆ™é•¿åº¦åˆ†æ•°ä¸º 0.5
                    if max_len == min_len:
                        norm_length_score = 0.5
                    else:
                        # çº¿æ€§å½’ä¸€åŒ–åˆ° [0, 1]
                        norm_length_score = (length - min_len) / (max_len - min_len)
                    #final_score = self.dialog_length(node) * final_score
                    final_score = (1 - rho) * final_score + rho * norm_length_score
                final_scores[node] = final_score
                
                debug_info.append({
                    "node": node,
                    "final": final_score,
                    "q_g": q_global,
                    "q_l": q_local,
                    "raw_mean": raw_rewards_mean[node],
                    #"length": self.dialog_length(node)  # store length for later use
                })

            # 3. æ’åºä¸é€‰æ‹©
            # æŒ‰æœ€ç»ˆå¾—åˆ†é™åºæ’åˆ—
            sorted_nodes = sorted(debug_info, key=lambda x: x['final'], reverse=True)
            
            # æ‰“å° Top 3 å’Œ Bottom 1 ç”¨äºè°ƒè¯•
            print(f"\n--- æœ€ç»ˆç»“æœæ’åº (Top 3) ---")
            for info in sorted_nodes[:3]:
                print(f"Node: {info['node'][:30]}... | Final: {info['final']:.4f} (Qg: {info['q_g']:.2f}, Ql: {info['q_l']:.2f})")
            
            # é€‰æ‹©æœ€ä½³å’Œæœ€å·®
            best_node_info = sorted_nodes[0]
            worst_node_info = sorted_nodes[-1]
            
            best_node = best_node_info['node']
            worst_node = worst_node_info['node']
            
            # é˜²å¾¡æ€§æ£€æŸ¥ï¼šå¦‚æœåªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œæˆ–æœ€ä½³æœ€å·®ç›¸åŒ
            if best_node == worst_node and len(sorted_nodes) > 1:
                worst_node_info = sorted_nodes[-1] # ç¡®ä¿å–åˆ—è¡¨æœ€åä¸€ä¸ª
                worst_node = worst_node_info['node']

            # 4. æ•°æ®ç»„è£…
            # æå– Thinking (Chain of Thought)
            c_reasoning = self.thinks_bank.get(best_node, "")
            j_reasoning = self.thinks_bank.get(worst_node, "")
            
            # æå–ç”Ÿæˆè¯¥èŠ‚ç‚¹æ—¶ä½¿ç”¨çš„ System Prompt (Meta Prompt)
            # åˆ—è¡¨å–æœ€åä¸€ä¸ª [-1] ä»£è¡¨å½“å‰ç”Ÿæ•ˆçš„
            chosen_meta_prompt = self.node_meta_prompts.get(best_node, [self.system])[-1]
            final_query = self.query

            # [æ–°å¢] è·å–èŠ‚ç‚¹å¯¹åº”çš„æ¨¡å‹ä¿¡æ¯
            chosen_model_info = self.node_model_mapping.get(best_node, {"model_name": "unknown", "organization": "unknown"})
            rejected_model_info = self.node_model_mapping.get(worst_node, {"model_name": "unknown", "organization": "unknown"})

            # æ„å»º Chosen å†…å®¹å—
            chosen_msg = {
                "role": "assistant", 
                "content": best_node, 
                "reasoning_content": c_reasoning,
                # [æ–°å¢] ç»‘å®šæ¨¡å‹ä¿¡æ¯
                "model_info": chosen_model_info
            }
            
            # æ„å»º Rejected å†…å®¹å—
            rejected_msg = {
                "role": "assistant", 
                "content": worst_node, 
                "reasoning_content": j_reasoning,
                # [æ–°å¢] ç»‘å®šæ¨¡å‹ä¿¡æ¯
                "model_info": rejected_model_info
            }
            # åœ¨ç»„è£… output_dict ä¹‹å‰ï¼Œè·å–æœ€ä½³èŠ‚ç‚¹çš„è¯¦ç»†è¯„ä¼°ä¿¡æ¯
            # å– evaluations_bank ä¸­æœ€åä¸€æ¬¡è¯„ä¼°è®°å½•
            best_eval_info = self.evaluations_bank.get(best_node, [{}])[-1]
            worst_eval_info = self.evaluations_bank.get(worst_node, [{}])[-1]
            output_dict = {
                "prompt": [
                    {"role": "system", "content": self.default_system + "\n" + chosen_meta_prompt},
                    {"role": "user", "content": final_query}
                ],
                "chosen": [chosen_msg],
                "rejected": [rejected_msg],
                # --- [æ–°å¢] ç‹¬ç«‹æŒ‡æ ‡è¾“å‡º ---
                "metrics": {
                    "use_diversity_fusion": self.use_diversity_fusion,
                    "chosen_quality": best_eval_info.get("quality_score", 0),
                    "chosen_diversity": best_eval_info.get("diversity_score", 0),
                    "chosen_final_reward": best_eval_info.get("final_reward", 0),
                    "rejected_quality": worst_eval_info.get("quality_score", 0),
                    "rejected_diversity": worst_eval_info.get("diversity_score", 0),
                },
                # è¯¦ç»†åˆ†æ•°è®°å½•
                "chosen_Q_score": best_node_info['final'],
                "rejected_Q_score": worst_node_info['final'],
                "chosen_raw_reward": best_node_info['raw_mean'],
                "rejected_raw_reward": worst_node_info['raw_mean'],
                "Q_score_diff": best_node_info['final'] - worst_node_info['final'],
                # è¾…åŠ©ä¿¡æ¯
                "domain": self.domain,
                "category": self.class_tag,
                "uid": self.uid,
                "model_config": {
                    "alpha": alpha,
                    "strategy": " Em-Mcts (EBC + Bradley-Terry) + Arena Model Selection",
                    # [æ–°å¢] æ¨¡å‹ä¿¡æ¯æ±‡æ€»
                    "chosen_model": chosen_model_info,
                    "rejected_model": rejected_model_info,
                    # [æ–°å¢] æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
                    "model_usage_stats": self.get_model_usage_stats()
                },
                # [æ–°å¢] Tokenä½¿ç”¨ç»Ÿè®¡
                "token_usage": {
                    "total_prompt_tokens": self.total_prompt_tokens,
                    "total_reasoning_tokens": self.total_reasoning_tokens,
                    "total_completion_tokens": self.total_completion_tokens,
                    "total_tokens": self.total_tokens,
                    "total_api_calls": self.total_api_calls
                }
            }

            # è¡¥å…¨åŸ input_dict ä¸­å¯èƒ½å­˜åœ¨çš„å…¶ä»–é¢å¤–å­—æ®µ
            for key, value in inputs.items():
                if key not in output_dict and key != "prompt":
                    output_dict[key] = value

            return [output_dict]

        except Exception as e:
            print(f"å¤„ç†ç»“æœæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return []

# --- å¼‚æ­¥è¿è¡Œå…¥å£ ---
async def run_llm_query():
    # æ¨¡æ‹Ÿåˆå§‹åŒ–é€»è¾‘
    tokenizer_path = "Qwen2.5-7B-Instruct-AWQ"
    try:
        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, trust_remote_code=True)
    except:
        tokenizer = None # Mock
        
    query = {}
    query["prompt"] = [{"role":"system", "content": "You are a helpful assistant."},
                       {"role":"user", "content": """æœ€è¿‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¦‚ä½•ç¼“è§£ç„¦è™‘ï¼Ÿ"""}]
    llm = LLM_Core(
        tokenizer,
        use_async=True,
        api_model="gpt-4.1-2025-04-14",
        base_url="<your-base-url>",
        api_key='<your-api-key>')
    rag = await AsyncFaissRAG.create(api_url="http://localhost:60046/emb/v1")
    
    # [æ–°å¢] å¯ç”¨çŠ¶æ€è¿½è¸ªå’Œå¯è§†åŒ–çš„ç¤ºä¾‹
    explorer = LLMExplorer_Socrates(
        llm=llm, 
        rag=rag, 
        max_iter=2, 
        use_diversity_fusion=False,
        # [æ–°åŠŸèƒ½] å¯ç”¨çŠ¶æ€è¿½è¸ªå’Œå¯è§†åŒ–
        enable_state_tracking=True,           # å¼€å¯çŠ¶æ€è®°å½•
        state_save_path="./rollout_data",     # çŠ¶æ€ä¿å­˜ç›®å½•
        auto_save_interval=1,                 # æ¯1æ¬¡è¿­ä»£è‡ªåŠ¨ä¿å­˜
        enable_visualization=True,              # å¼€å¯å¯è§†åŒ–
        use_expert_prompt=True
    )
    
    print("ğŸš€ å¼€å§‹ Em-Mcts Arenaæ ‘æœç´¢ (å·²å¯ç”¨çŠ¶æ€è¿½è¸ª)")
    dicts = await explorer.main_loop(query)
    print("âœ… æœç´¢å®Œæˆï¼")
    
    print(f"ğŸ“Š æœ€ç»ˆç»“æœ: {dicts[0]}")
    
    # [æ–°å¢] æ¼”ç¤ºçŠ¶æ€æ¢å¤åŠŸèƒ½
    print("\nğŸ”„ æ¼”ç¤ºçŠ¶æ€æ¢å¤åŠŸèƒ½...")
    if hasattr(explorer, 'state_file') and explorer.state_file:
        # åˆ›å»ºæ–°çš„æ¢ç´¢å™¨å®ä¾‹
        new_explorer = LLMExplorer_Socrates(
            llm=llm, 
            rag=rag, 
            max_iter=8,  # å¯ä»¥è®¾ç½®æ›´å¤šè¿­ä»£
            use_diversity_fusion=True,
            enable_state_tracking=True,
            state_save_path="./rollout_data_continued",
            auto_save_interval=2,
            enable_visualization=True
        )
        
        # åŠ è½½ä¹‹å‰çš„çŠ¶æ€
        if new_explorer.load_state(explorer.state_file):
            print("âœ… çŠ¶æ€æ¢å¤æˆåŠŸï¼å¯ä»¥ç»§ç»­rollout...")
            
            # ç»§ç»­æœç´¢æ›´å¤šè¿­ä»£
            print("ğŸ”„ ç»§ç»­è¿›è¡Œæ ‘æœç´¢...")
            continued_dicts = await new_explorer.main_loop(query)
            print("âœ… ç»­æœç´¢å®Œæˆï¼")
            print(f"ğŸ“Š ç»­æœç´¢ç»“æœ: {continued_dicts[0]}")
        else:
            print("âŒ çŠ¶æ€æ¢å¤å¤±è´¥")
    
    # [æ–°å¢] è¾“å‡ºæ–‡ä»¶ä½ç½®ä¿¡æ¯
    if hasattr(explorer, 'visualization_file') and explorer.visualization_file:
        print(f"\nğŸ“ˆ å¯è§†åŒ–æ–‡ä»¶å·²ç”Ÿæˆ: {explorer.visualization_file}")
        print(f"ğŸ“ æ“ä½œæ—¥å¿—æ–‡ä»¶: {explorer.operation_file}")
        print(f"ğŸ’¾ çŠ¶æ€æ–‡ä»¶: {explorer.state_file}")
        print(f"\nğŸŒ æ‰“å¼€ {explorer.visualization_file} æŸ¥çœ‹äº¤äº’å¼å¯è§†åŒ–ï¼")

# [æ–°å¢] ç‹¬ç«‹çš„çŠ¶æ€æ¢å¤ç¤ºä¾‹å‡½æ•°
async def demo_state_recovery(state_file_path: str):
    """æ¼”ç¤ºå¦‚ä½•ä»ä¿å­˜çš„çŠ¶æ€æ¢å¤å¹¶ç»§ç»­rollout"""
    print(f"ğŸ”„ ä»çŠ¶æ€æ–‡ä»¶æ¢å¤: {state_file_path}")
    
    # åˆå§‹åŒ–LLMå’ŒRAGï¼ˆå®é™…é¡¹ç›®ä¸­åº”è¯¥ä¿æŒä¸€è‡´ï¼‰
    llm = LLM_Core(
        None,  # tokenizer
        use_async=True,
        api_model="gpt-4.1-nano-2025-04-14",
        base_url='<your-base-url>',
        api_key='<your-api-key>'
    )
    rag = await AsyncFaissRAG.create() #api_url="http://172.21.30.231:60046/emb/v1"
    
    # åˆ›å»ºæ¢ç´¢å™¨å¹¶æ¢å¤çŠ¶æ€
    explorer = LLMExplorer_Socrates(
        llm=llm, 
        rag=rag, 
        max_iter=10,  # å¯ä»¥è®¾ç½®æ›´å¤šè¿­ä»£ç»§ç»­æœç´¢
        use_diversity_fusion=True,
        enable_state_tracking=True,
        enable_visualization=True
    )
    
    if explorer.load_state(state_file_path):
        print(f"âœ… çŠ¶æ€æ¢å¤æˆåŠŸï¼å½“å‰è¿­ä»£: {explorer.iter}")
        print(f"ğŸ“Š å½“å‰èŠ‚ç‚¹æ•°: {len(explorer.answers_list)}")
        
        # æ„å»ºç»§ç»­æœç´¢æ‰€éœ€çš„inputsï¼ˆä»çŠ¶æ€ä¸­æ¢å¤ï¼‰
        inputs = {
            "prompt": [
                {"role": "system", "content": explorer.system},
                {"role": "user", "content": explorer.query}
            ],
            "domain": explorer.domain,
            "class_tag": explorer.class_tag
        }
        
        # ç»§ç»­æœç´¢
        print("ğŸš€ ç»§ç»­æœç´¢...")
        results = await explorer.main_loop(inputs)
        print("âœ… ç»§ç»­æœç´¢å®Œæˆï¼")
        return results
    else:
        print("âŒ çŠ¶æ€æ¢å¤å¤±è´¥")
        return None

if __name__ == "__main__":
    try:
        asyncio.run(run_llm_query())
    except Exception as e:
        print(f"Error: {e}")